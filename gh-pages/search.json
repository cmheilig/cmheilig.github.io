[{"path":"index.html","id":"preface-on-doing-good-things-with-data","chapter":"Preface: On doing good things with data","heading":"Preface: On doing good things with data","text":"Everyone wants good things data intellectual\nsupport , long proceed rigor stand behind \nwork. credo—fundamental, animating belief culture \ngood things data public health.essay presents views developed throughout career, especially\n8-year tenure Associate Director Data Science CDC’s\nCenter Surveillance, Epidemiology, Laboratory Services January 2015\nCSELS’s dissolution January 2023. drafted essay primarily \nearly 2022 bring together coherent whole several related ideas \nCDC think, talk , support work culture oriented good\nthings data. view, CDC’s single greatest area gains \ngood things data: connecting technical excellence analytic rigor\nscience better, getting better learning things world, \ngetting better things learned. experience, CDC\ntended overemphasize technology underemphasize critical reflection\npractical wisdom things data.next 4 sections, expand care good things\ndata, data science , construct support \nculture good things data, plays various roles \ncarries functions culture good things data. \npenultimate section, add personal history data science. extend\ndiscussion machine learning artificial intelligence salient,\ncontemporary set issues good things data. Finally, cap \nessay aspirational declaration creating fostering progressive\nculture data public health.essay snapshot time. reaches back extensive reading study\nundertook 2014 2016, stops around 2021. field\ncontinues change rapidly. much data science keeping \nfast-moving methods, tools, technology, schema data science \nstable. , example, describe CDC think \nmachine learning artificial intelligence, don’t specifically address\nrecent large language (“chat”) models.dedicate essay dozens folks mentored since joined\nCDC federal employee February 2000. believe . ’re reason\nwholeheartedly believe progressive culture data centers \nlearners—learners believe.PDF version essay available.","code":""},{"path":"introduction.html","id":"introduction","chapter":"1 Introduction: Why, what, how, and who","heading":"1 Introduction: Why, what, how, and who","text":"Data science acts belief approach data just right way,\ncan discover unlock meanings. data become varied \ncomplex, data science helps removing impediments data’s meanings \ndata limits, data go unlearned. Sometimes approach data\ngently, data-whisperer intent codiscovering data \npotential reveal things world inform action world.\nSometimes wade gingerly; sometimes dive ; sometimes catch \nride waves story within data comes surface.’s easy skeptical concept data science, especially \nseems like means many things much anything. “Data science \ndata scientists ,” wrote Davenport Patil (2012). \nphrase convey anything substantive? offer anything new compared, say, \ndata-oriented fields statistics informatics? Let’s open ,\n, , data science unpack themes.: Foremost, data science learning data. purpose \nbroadly bring together, rigorous way, goes good\nthings data. Data science promotes principled use full breadth \nmethods, familiar unfamiliar, along norms ensure\nmethods results stand scrutiny. Data science helps us keep\nevolving methods, tools, technology learning data \nstructures, sizes, shapes, speeds way disciplines .\nDynamic complex technologies data motivate define data\nscience.: Data science studies learn data—especially complex \nnontraditional data. combines analytic, computational, subject-matter\nmethods connect whole life cycle data: Frame want figure\n. Obtain prepare data engage question. Preserve share \nlearned, learned, learning fits \nalready known choices made.: individual level, data science calls technical \nnontechnical skills. collective level, calls forward-looking\ngrounded culture supports putting skills use good\nthings data. Technical skills cover analytic methods, statistics,\nmachine learning, causal inference, computational methods, data\nwrangling implementing scaling algorithms. Nontechnical skills support\ngood science generally good data science specifically, ability\napproach problem curiosity, attentiveness, perseverance,\nopen-mindedness, creativity.: Everyone wants good things data get make \neffort, long rigorous accountable. rich culture data\nscience includes expert nonexpert doers, learners, mentors, supporters,\nadvocates, organized operate keep fast-moving methods,\ntools, technology good things data effectively \nsustainably.unpack 4 circumstances—, , , —next 4\nsections.","code":""},{"path":"why.html","id":"why","chapter":"2 Why","heading":"2 Why","text":"purpose data science broadly bring together, rigorous way, \ngoes good things data—learning data \nbuilding things data put learnings use, example, \nsafeguarding public health. CDC consumes lot data support public\nhealth mission. Traditional sources include surveillance, vital records,\nsurveys, program evaluation, studies health services, clinical trials.\nrecent sources include billing claims data, electronic health records,\nsocial media, sensor data. small, structured data high-volume,\nunstructured data, time scope scale data expand become\ncomplex.focus data science? need keep rapidly\nchanging methods, tools, technology extracting meaning data.Data science makes available tools classic problems, working \ndata life cycle problem formulation collection data\nmanagement, analysis, interpretation, presentation. Contemporary\nissues data science arise movements open expand scale\ndata sophistication analytic methods. Making data available wide\naudiences, ensuring adequate protections individual privacy. Describing\npractices make analyses reproducible, least traceable. Working \nhigh-volume data, genomics, high-velocity, real-time data, found\nsyndromic surveillance claims data feeds. making sense \nunstructured text, images, nontraditional data types. \ncontemporary problems differ classic problems scale rather kind.\nexample, whether administrative data come paper-based registers \nresource-constrained settings massive stores insurance claims data,\npose problems inferring causes. Data science promotes\nprincipled use full breadth methods, familiar \nunfamiliar, along norms ensure methods results stand \nscrutiny. Data science crosses disciplines.’s another reason focus data science: Data science affords measure\nautonomy practicing honing data skills, ready access \nopen methods, tools, technology. technical skills require special\nequipment (like growth media microscopes microbiology laboratory) \naccess humans (like clinical medicine behavioral counseling). contrast,\nlearn data data, often enough data hand,\nwidely available software, persistence jump problem break\nopen. Software now often freely available, growing contributions \nactive R Python user communities. data science can practiced\ngreat deal self-determination. autonomy comes latitude\ndirect one’s learning. Thus, enterprising scientist can\ncapitalize autonomy order keep fast-moving methods, tools,\ntechnology, part continuing learn learn data. \nautonomy presents paradox try resolve later (section 5.4.2): Data science necessarily interdisciplinary, every\npractitioner needs cross disciplines. can one autonomous\nteam-oriented time?summary, focus data science want learn data, learn\ndata, learn data.Learning data: Data value data help us learn things\nworld. learn helps us make informed choices \ninteract world, example, public health interventions.Learning data: Data come many structures, sizes, shapes, \nspeeds, small, flat data tables massive, unstructured data streams. Data\nconform variety standards, standards . varied\ncharacteristics data enrich constrain ways data reveal\ncharacteristics world.Learning data full life cycle: Analytic knowledge \nskills allow us pose rich questions world, amenable rich\nmethods; guide generate, transmit, obtain, prepare data; probe data\nanswer questions world; place answers data context, mindful\nassumptions alternatives; present data-driven answers audiences\nclearly correctly; preserve answers ensure entire\nlife cycle transparent, accessible, traceable , extent possible,\nreproducible.field data science addresses wide variety problems (), \npractice data science straddles autonomous collaborative styles ().\nThus, also focus data science can build sustain culture\n() good things data, continuously learning things \nworld, empowering choices informed learnings, \never ready learn act data.","code":""},{"path":"what.html","id":"what","chapter":"3 What","heading":"3 What","text":"","code":""},{"path":"what.html","id":"what-is","chapter":"3 What","heading":"3.1 What data science is","text":"shortage definitions “data science”, different\ndefinitions serve different purposes. start tautological\ndescription almost amounts operational definition.","code":""},{"path":"what.html","id":"data-science-is-what-data-scientists-do","chapter":"3 What","heading":"3.1.1 Data science is what data scientists do","text":"Writing 2012 Harvard Business Review, Tom Davenport DJ Patil\n(US Chief Data Scientist Obama Administration) wrote \nfollowing:[W]hat data scientists make discoveries swimming data. … \nease digital realm, able bring structure large\nquantities formless data make analysis possible. identify rich\ndata sources, join , potentially incomplete data sources, \nclean resulting set. [D]ata scientists help decision makers shift ad\nhoc analysis ongoing conversation data. Data scientists realize\nface technical limitations, don’t allow bog \nsearch novel solutions. [T]dominant trait among data scientists\nintense curiosity—desire go beneath surface problem, ﬁnd\nquestions heart, distill clear set \nhypotheses can tested. (Davenport Patil 2012)","code":""},{"path":"what.html","id":"learning-from-data","chapter":"3 What","heading":"3.1.2 Learning from data","text":"pith, can turn Donoho (2017): “Data science [] science \nlearning data, entails,” adds, “studies\nmethods involved analysis processing data proposes\ntechnology improve methods evidence-based manner.”plainness, can turn working definition: “set core activities\nask good scientific questions line tools answer \nrigorously using data.” developed formulation 2016, drawing \nArt Data Science (Peng Matsui 2015). operating definition data science\nlinks rather separate tasks stating solving problems, mediated\ndata. Peng Matsui enumerated 5 core activities, add \nsixth. explicitly link 6 core activities analysis, since data\nanalysis central commitment data science, explain .Pose good questions. set potential questions enriched \nawareness kinds learning various analytic methods support.Prepare data address questions. purposes analysis \nmind, practitioner can obtain, manage, explore data ensure \ndata’s fitness address analytic purposes.Probe data. Conduct rigorous analysis address questions, \nincludes developing critically assessing one analytic models. \nvalue analysis comes ability answer question \nconvey learned data.Place analytic results context. Interpretation binds question \nmethod, binds method result, puts context\nassumptions data, technical assumptions analytic models,\nexisting domain knowledge, alternative analytic approaches \nconsidered. Understanding specific data can’t tell , \nphenomena data rule , valuable interpreting data\nshow.Present methods results. Communication shares learned\ndata learned, also subjects life cycle \nscrutiny transparency.Preserve entire life cycle. Ensure life cycle traceable,\naccessible, reproducible, enduring extent possible. addition \ncommunicating methods results, transparency ensures data \nanalytic code available possible, subject privileges access\nnecessary. transparency turn supports fundamental scientific\nnorms.Peng Matsui took care explain core activities need ,\noften , occur sequence. Rather, execution core\nactivity, careful reflection lead practitioner repeat, jump back,\njump forward. expand idea later section.Blei Smyth (2017) wrote, “Although [statistical, computational, \nhuman perspectives] critical component data science, argue \neffective combination three components essence data\nscience . ... practice data science just single step \nanalyzing dataset. Rather, cycles data preprocessing, exploration,\nselection, transformation, analysis, interpretation, communication. One \nmain priorities data science develop tools methods \nfacilitate cycle.”Data Science Association focuses \nmeaning:\nData science “scientific study creation, validation \ntransformation data create meaning” , data scientist “\nprofessional uses scientific methods liberate create meaning raw\ndata.” (Data Science Association)National Institutes Health Strategic Plan Data Science defined \n“interdisciplinary field inquiry quantitative analytical\napproaches, processes, systems developed used extract knowledge\ninsights increasingly large /complex sets data.”\n(National Institutes Health 2018)National Academies Sciences, Engineering, Medicine described data\nscience along relationship fields, primary tasks, \nprimary purposes:[Data science centers ] multidisciplinary interdisciplinary approaches\nextracting knowledge insights data use broad range \napplications. field science relies processes systems\n(mathematical, computational, social) derive information insights\ndata. synthesizing relevant parts \nfoundational disciplines solve particular classes problems \napplications also creating novel techniques address ‘cracks’\ndisciplines approaches may yet exist … \nvolume variety data available expanding swiftly, data \navailable immediately, decisions based data increasingly automated\nreal time. (National Academies Sciences, Engineering, Medicine 2018)Finally, National Institute Standards Technology (NIST) 2015\ndefined data science “Extraction actionable knowledge directly \ndata process discovery, hypothesis formulation hypothesis\ntesting.” Per NIST, data scientist “practitioner sufficient\nknowledge overlapping regimes business needs, domain knowledge,\nanalytical skills, software systems engineering manage end--end\ndata processes data life cycle … end--end role ensures \neverything performed correctly explore data, create validate\nhypotheses.” (NIST Big Data Public Working Group 2015) data life cycle\n“set processes application transform raw data actionable\nknowledge”:Collection: Gather store raw data.Collection: Gather store raw data.Preparation: Convert raw data cleansed, organized information.Preparation: Convert raw data cleansed, organized information.Analysis: Synthesize knowledge organized information.Analysis: Synthesize knowledge organized information.Action: Use synthesized knowledge generate value enterprise.Action: Use synthesized knowledge generate value enterprise.NIST’s definitions appear context discussing “big data” \naccommodated traditional architectures. Data volume (size), variety (sources,\ndomains, types), velocity (rate flow), variability (changing\ncharacteristics) “drive shift … architectures data-intensive\napplications.” (NIST Big Data Public Working Group 2015)\nprefer plain-language versions concepts:Attributes “big data”varied definitions data science explicitly invoke learning, answering\nquestions, creating meaning, extracting knowledge—epistemic tasks \ntake us nature, sources, structure, limits empirically derived\nknowledge. Learning defines data science, turn centers data science \nrole analysis. definitions vary whether appeal \nprocesses (data life cycle adaptive problem-solving), means\n(complex data), methods (quantitative analytical approaches \ntechnology). definitions also suggest enumerate skills \nneeded data science.agree NIH NASEM definitions current evolving\ncomplexity drive need adapted methods. data technologies become\ncomplex, drive adaptively learning data also intensifies. \nrisk see might overinvest narrow (potentially useful) skills\ngiving short shrift broadly applicable underserved skills: \nrespect fundamentals avoid unfortunate tendency \noveremphasize exotic complex expense fundamentals.\nIndeed, Donoho (2017) makes similar case. lose sight need\nlearning conventional familiar data, using conventional familiar\nmethods. addition basic skills managing analyzing data, need\nalways esteem skills critical reflection reasoning creative \ndisciplined ways. sense, complexity sophistication motivate data\nscience, define data science, mistake \noveridentify data science drivers. also mistake \nfocus technology rather science: Learning data \nscientific act, enabled evolving methods tools. value learning\ndata needs judged scientific rather technological norms. \nposed questions social value scientific validity? (See also Freedman 1987.) prepared data answer questions?\nadequately probed data placed findings context? proposed\nconclusions traceable defensible? reasoning coherent? return\npoint talk data science done.","code":""},{"path":"what.html","id":"core-activities-and-critical-reflection","chapter":"3 What","heading":"3.1.3 Core activities and critical reflection","text":"mentioned , Peng Matsui’s schema core activities art\ndata science goes deeper merely listing activities: core\nactivity calls critical reflection, practitioner reviews \ncore activity framing, checking, possibly revising revisiting \nactivity.First, set expectations core activity. collect information \ncompare expectations information. don’t match, take\nanother look either revise expectations information. Maybe\nrepeat current core activity return previous one. match,\n’re good place, occasionally check good\nmeasure, lest fall confirmation bias trap.real sense, critical reflection puts science data science. \ncan associate core activity example prompts critical reflection.Pose good questions. question interest? Valid valuable?\nConsult experts literature. needed, revise question.Prepare data address questions. data suited \nquestion? Examine data early often learn structure, content, \nsuitability. needed, refine question obtain different data.Probe data. analytic model answer question? use\ndata correctly take suitable form explaining predicting \nphenomenon interest? Challenge model assumptions structure. needed,\nrevise model structure inputs.Place analytic results context. analysis provide meaningful\nanswer holds scrutiny contributes domain knowledge? Assess\ntotality analyses—effect sizes, accuracy bias, variability \nuncertainty—consideration varying assumptions data, \nmodel, subject-matter context question. needed, revise \nanalysis provide specific, meaningful answer conduct diagnostics \nsensitivity analyses assess limitations assumptions.Present methods results. methods results understood,\ncomplete, meaningful audience? Assess content, style, attitude\ngauge audience feedback. needed, revise presentation suit\naudience needs.Preserve entire life cycle. data analysis open \ntransparent possible? Assess whether data analytic code can made\navailable without alteration access controls, example, \npublic repositories user agreements. needed, work toward least\nrestrictive means sharing.critical reflections show core activities need occur \nsequence. Indeed, core activities occur \ngiven undertaking.Core activities, critical reflection, iterationCore activities critical reflections adapted, part, \nPeng Matsui (2015).","code":""},{"path":"what.html","id":"commitments-life-cycle-centered-on-analysis-subject-to-norms","chapter":"3 What","heading":"3.1.4 Commitments: life cycle, centered on analysis, subject to norms","text":"taken broad view surveying variety motivations definitions\ndata science. consideration breadth variety, contend \ndata science entails 3 main commitments:learn data context overall life cycle: posing rich\nquestions world, amenable rich methods; guiding \ngenerate, transmit, obtain, prepare data; probing data answer\nquestions world; placing answers data context, mindful \nassumptions alternatives; presenting data-driven answers audiences\nclearly correctly; preserving answers ensure \nentire life cycle transparent, accessible, traceable , extent\npossible, reproducible.learn data context overall life cycle: posing rich\nquestions world, amenable rich methods; guiding \ngenerate, transmit, obtain, prepare data; probing data answer\nquestions world; placing answers data context, mindful \nassumptions alternatives; presenting data-driven answers audiences\nclearly correctly; preserving answers ensure \nentire life cycle transparent, accessible, traceable , extent\npossible, reproducible.Analysis centrally connects life cycle data. pose questions,\nprepare data, place results context, present answers informed \nvariety available analytic approaches. methods analyzing\nimages, can ask questions images can answer. interpret\ncommunicate risk rate change seen set data, infer\nmeaning analytic method. discussed , many\nanalytic modes available us beyond traditional statistical methods, \ncausal inference machine learning.Analysis centrally connects life cycle data. pose questions,\nprepare data, place results context, present answers informed \nvariety available analytic approaches. methods analyzing\nimages, can ask questions images can answer. interpret\ncommunicate risk rate change seen set data, infer\nmeaning analytic method. discussed , many\nanalytic modes available us beyond traditional statistical methods, \ncausal inference machine learning.judge data science approaches claims scientific norms. Since\ndata science extracting knowledge analyzing data, \njudged criteria apply extracting knowledge\nobservations. commitment familiar within statistical practice;\nneeds become familiar data-analytic modes, including\nmachine learning.judge data science approaches claims scientific norms. Since\ndata science extracting knowledge analyzing data, \njudged criteria apply extracting knowledge\nobservations. commitment familiar within statistical practice;\nneeds become familiar data-analytic modes, including\nmachine learning.3 commitments unpack means learn data, set \nboundaries around practice. point practitioner’s responsibility\nrespecting context, respecting analytic intent, respecting quality \nrigor. also point us direction needed investments resources\nlearning. commitments , however, meant imply \nperson practices data science individually carries activity. (See\nalso section 5.3.) Let’s examine boundaries disciplines\nrelated , distinct , data science.","code":""},{"path":"what.html","id":"what-is-not","chapter":"3 What","heading":"3.2 What data science is not","text":"Data science overlaps disciplines scientific practices. Furthermore,\nNational Academies Sciences, Engineering, Medicine (2018) notes, practice data\nscience necessarily crosses disciplines. data science relate \nstatistics modes data analysis, informatics, science \ngeneral? practice data science privilege science \ntechnology focus meaning rigor?","code":""},{"path":"what.html","id":"data-science-is-not-statistics","chapter":"3 What","heading":"3.2.1 Data science is not statistics","text":"Statistics data science, though field substantially\noverlaps data science. Moreover, data science merely statistics\ndressed appealing marketing. argue data science takes\nresponsibility whole life cycle data, connected centrally \nanalytic concerns. understanding, statistician limits \nengagement solely analysis perhaps interpretation data\nscience. statistician analysis engages rest life cycle\ndata data science—epidemiologist, sociologist, \nmicrobiologist, anyone else.Donoho (2017) Jones (2018) show data science took shape \ndiscipline, part, reaction failure academic statistics focus\nsufficiently pragmatic rather theoretical concerns. \ncharacterization cuts 2 directions: academic statistics might \nshunned practical concerns, academic applied statistics firmly root\ntraditions rigor scientific norms. hand,\nmachine learning analytic disciplines firmly rooted. \nfair, academic machine learning—often located computer science \ninformation science departments—pays heed rigorous mathematics,\n--sample generalizability, applied issues bias fairness.\ntraditions deep, norms strong.Leo Breiman, late UC Berkeley statistics faculty member early\nbridge-builder statistical machine-learning communities, said \nmight advise young person (2001), “Don’t go statistics.” \nend, say, “Take statistics, remember great adventure \nstatistics gathering using data solve interesting important\nreal world problems.” (Olshen 2001)Andrew Gelman, Columbia faculty member prolific blogger, wrote 2013,\n“Statistics least important part data science … Statistics \nimportant—don’t get wrong … ’s important part data\nscience, even close.” (Gelman 2013)","code":""},{"path":"what.html","id":"data-science-is-not-data-analysis-not-even-machine-learning","chapter":"3 What","heading":"3.2.2 Data science is not data analysis (not even machine learning)","text":"field statistics connects disciplines practices constructing \nprobing models grounded probability theory inference. \ncharacterization holds frequentist, Bayesian, approaches, whether\nprobability model highly specified (parametric models) loosely\nspecified (nonparametric models). Many approaches data analysis\nmight probability component primary concern might \nformal probability component .Machine learning described answer question, “can\ncomputers learn solve problems without explicitly programmed?” \npractice, computers “learn” solve problems looking mathematically\nrepresentable patterns data (clusters topic models) \nconstructing mathematical tools guess output, given set inputs,\nmodeled examples associate known inputs known outputs. \nsenses, machine learning data analysis. field collection methods,\nmachine learning overlaps substantially statistics, distinguished \nemphasis finding patterns making predictions rather constructing\nmodels directly represent data—even machine learning model \nexplicitly probability-based model’s performance represented using\nconcepts probability.bright line statistics machine learning, many\nmethods inhere disciplines. example, classical statistics \ntraditions cluster analysis, dimensionality reduction, regularization,\nmachine learning uses Bayes’s theorem logistic regression binary\nclassification tasks. Although machine learning often associated complex\nmodels based vast amounts data, statistical models can complex, \nmany model parameters, can based large amounts data.\nConversely, machine learning models can simple based small data. Since\nmachine learning models tend emphasize predictive performance (outputs given\ninputs) rather internal model structure, however, largest data-analytic\nmodels practice tend use machine learning methods. deep learning\nmodels billions, possibly trillions, model parameters. discuss\nmachine learning, along artificial intelligence, greater length \nsection 8.modes data analysis beyond statistics include causal inference,\ngeospatial methods, econometric methods, compartmental agent-based\nmodeling. Pearl (2009) explicitly characterizes causal inference \nextrastatistical; without additional strong assumptions, probability model\ncan inherently represent causality. Structural equation models inverse\nprobability weighting can help disentangle causal signal random noise,\nsubject extrastatistical assumptions. Geospatial econometric\nmethods also often use probability components, example, accommodate\ncorrelations space time, wed components concepts.\nCompartmental agent-based modeling might might use empirical\nobservations, , probability components solving \nsimulating systems also extend beyond strictly probability-based models.perspective data science, life cycle data can center \nanalytic disciplines, just statistics. perspective\ncovers 2 3 commitments data science: life cycle central\nconcern data analysis. third commitment, scientific norms rigor,\nobtains practitioner acknowledges respects norms inherent \nvarious models analysis. machine learning, example, norms\ninclude --sample generalizability model robustness stability. Thus,\nwrong characterize data science enhanced form \nstatistics, characterization risks failing hold analytic modes\nsimilar expectations rigor norms.Much written whether machine learning modes \nanalysis reveal “meaning” data, data science definitions seek .\nnow, note modes, including statistics, can subjected \nvarious methods interpretation terms model structure \nrelationship models input data. Furthermore, interpretations \naccompanying explanations warrant careful critical evaluation view broad\nswath scientific norms, least apparent interpretation \nexplanation can illusion regardless method analysis.","code":""},{"path":"what.html","id":"data-science-is-not-informatics","chapter":"3 What","heading":"3.2.3 Data science is not informatics","text":"Public health informatics systematic application information \ncomputer science technology public health practice, research, \nlearning. Informatics applies technology obtain, store, use information.\nPer Savel Foldy (2012), concerns “technology systems\nversus common information technology … integration\nproper application technology systems get data rather just\ntechnology systems” (emphasis added) … “frequently application \nstandards structure help meaning data science gets .”\ncolleague Brian Lee said (personal communication), “Informatics \nwork understanding making data available determine meaning”. Thus,\ncan see informatics data science overlap, especially regarding data\nwrangling, movement, accessibility, scale, fields take different\norientations: Data science seeks meaning data, empowered informatics \nwork data. disciplines field important, one can\npractice collection disciplines across fields. important,\nhowever, conflate treat one field subset .","code":""},{"path":"what.html","id":"data-science-is-not-just-good-science","chapter":"3 What","heading":"3.2.4 Data science is not just good science","text":"Much scientific practice public health uses, purports use, data \ncome observations individual health status aspects \nworld. public health science uses data, conform \nscientific norms rigor, much claimed data science . \nfollow, , data science just good science? answer , \ndata science inherits commitments apply broadly \npractice science good science entails commitments \napply data science.“good science” mean, brief, practices building \norganizing knowledge world methods values \nexperiment observation, neutrality, rigor, transparency, empiricism,\nreproducibility, minimizing subjective bias, .expectation theoretical science need use data , can\nomit theoretical science narrow question applied science. Even\nnarrowed way, can conclude applied science uses data.\napplied science depends observation precedent, contexts\nneed entail data sense observations represented way \ncan subject analysis. example, without implicating data, \nscientist can classify organism observation conduct qualitative\nreview published literature structure arguments conclusions \nstate knowledge specified domain. Next, applied science \nuses data, uses well. argue applied science uses\ndata poorly “good science”, also acknowledge applied\nscience can consist good bad components poor use data\nundermine entire project. Finally, pivotally, applied\nscience uses data well also takes responsibility integrity \nlife cycle data connecting data life cycle questions \nposed, data obtained, analysis performed, results placed context, methods \nresults presented, whole process preserved. Just statistician can\nconduct rigorous data analysis without connecting analysis life\ncycle data, scientist can engage portions scientific\nmethod, including portions life cycle data, without applied\ndata science. Data science entails taking responsibility integrity \nlife cycle data—across core activities data science—way\napply full breadth “good science”. Without question,\ndata science well overlaps good science, important\nconflate .life cycle data consistent , synonymous , \nscientific method. distinction “good science” data science\nmatters distinction informs data science, turn\ndiffers emphasis kind good science. particular, \ntechnical nontechnical skills support practice data science,\nespecially skills locating data analysis central focus life\ncycle data, generalize scale wholesale conduct good\nscience.","code":""},{"path":"how.html","id":"how","chapter":"4 How","heading":"4 How","text":"","code":""},{"path":"how.html","id":"foster-a-progressive-culture","chapter":"4 How","heading":"4.1 Foster a progressive culture","text":"think data asset, asset produce value\nwithin mission available resources? can public health\nscientists care data keep fast-moving methods, tools,\ntechnology learning data? progressive culture\nintentionally orients proactively reactively, toward\nadvancement just tradition. progressive culture\nencourages innovation, importantly community continually\nexpands set tools good things data applies\njudgment selecting among familiar conventional options well \nunfamiliar unconventional options. progressive culture data\nremains rooted history, continues learn old data new ways,\nanticipates future, handles evolving demands keep \nfast-moving methods, tools, technology.sketch vision fostering practice data science across\ndisciplines levels experience describing 3 components \nprogressive culture data:developing know-data-savvy technical skills \nbridge domain knowledge methods learning data,developing know-data-savvy technical skills \nbridge domain knowledge methods learning data,cultivating data-wise nontechnical skills drive\nproblem-solving data (start inquiry, keep track, deal\nobstacles), andcultivating data-wise nontechnical skills drive\nproblem-solving data (start inquiry, keep track, deal\nobstacles), andparticipating empowering community mentors peers \nenable self-learning foster practical wisdom.participating empowering community mentors peers \nenable self-learning foster practical wisdom.describing technical nontechnical skills, map skills\nexpanded treatment Peng Matsui’s core activities data\nscience. sketch functions roles empowering community.\nnext section, data science, fully articulate\nfunctions roles along level technical \nnontechnical skill needed .","code":""},{"path":"how.html","id":"technical-skills","chapter":"4 How","heading":"4.2 Foster technical skills","text":"skills required practice data science rigorously? \nwant need practice data science well don’t need\nexpert data scientists? core activities data science call\nknowing pose good question, compile prepare \ndata answer question, extract, interpret, convey\nmeaning data answer question. Data science skills \noften represented (example, NIST Big Data Public Working Group (2015)) cross-disciplinary\nintersection 3 sets technical skills cover core\nactivities: domain-specific skills posing good question \ninterpreting explaining results; computational skills \ncorralling, structuring, applying algorithms data; \ndata-analytic skills, including communication skills, extracting,\ninterpreting, conveying meaning data.Domain-specific skills cover subject one might want\nuse data answer question, including public health, epidemiology,\nmedicine, microbiology, toxicology, anthropology. practice,\ndifferent fields often call different norms rigor. Epidemiology\nestablishes modes reason bias causation. Medicine\ninstitutes norms assessing preventive therapeutic efficacy \neffectiveness. Microbiology toxicology work establish \nmeasure presence pathogen toxin ascertaining individual\ncases.Computational skills cover use theory, hardware, software\nrepresent work data various structures, sizes, shapes,\nspeeds, enable transmission exchange data \ninformation among systems among users, implement algorithms \nworking analyzing data, manage efficiency \nundertakings. textual information, audiovisual\ninformation, types information represented \ncomputational access use? obtained stored various types\ninformation, processed arranged preparation\nanalysis? can algorithms working data make best use\navailable computational resources, memory processing\ntime? can algorithms implemented work increasing volumes,\nspeed, complexity data ensuring computational results\navailable acceptable amount time limitations?\nComputational skills cover overlap programming, data-wrangling,\nsoftware engineering, statistical computing, methods breaking \nhigh-volume, high-velocity, otherwise intensive data problems \nsmaller pieces, processing , reassembling output.Data-analytic skills, discussed , encompass statistical\nmethods, machine learning, modes data analysis. Statistical\nmodeling typically refers using probability think data\nmight generated using data figure might\nseparate representation something world (signal) \nvariability uncertainty representation (noise).\nStatistical methods include simple summaries like means medians \ncomplicated summaries like tables, regression models, \ntime--event models. Machine learning typically refers asking\nwhether can find patterns within set data, like clusters \nsimilar counties patients topics set documents, \npatterns relate inputs outputs based examples, \npredicting patient’s disease status prognosis available\ninsurance claims billing information. data-analytic approaches\ninclude causal, geospatial, econometric methods. methods often\noverlap, often incorporate don’t always center \nprobability components.include communication skills primarily data-analytic skills,\nanalyst often primary responsibility interpreting,\nrepresenting, conveying methods results. skills include\nability use verbal narrative, tables, graphics explore,\ndevelop, tell story translates results stories,\ndecisions, actions.data science often represented 3-way intersection \ndomain-specific, computational, data-analytic skills, also\ninstructive review pairwise overlap. combination \ndomain-specific computational skills encompass domain-specific\nsoftware development, medical laboratory applications.\nDomain-specific data-analytic skills entail applied research, \nepidemiological applications. computational data-analytic skills\noverlap statistical computing, machine learning, \napplications implement mathematical algorithms optimization.can roughly associate core activity data science \ntechnical skill areas.Pose good questions. Domain knowledge needed state \nrefine good question. awareness understanding broad \nrich variety data-analytic methods can also enhance kinds \nquestions one pose.Prepare data address questions. Domain knowledge informs\nmeasure assess, computational skills inform \nobtain, organize, store, transmit, extract, transform data.\nData-analytic skills support assessments whether data can\nanswer question.Probe data rigorous analysis. Building formal model\ndepends primarily data-analytic skills, supported strong\ncomputational skills implementing analysis, especially \nworking complex data methods.Place analytic results context. Interpreting models depends \ndata-analytic skills construct critique\nmodel-related assumptions, well domain knowledge place \nresults context already known perceived \ndomain subject.Present methods results. Communication draws data-analytic\nskills correctly describing methods formal results, well \ndomain knowledge correctly describing relating \nsubject-matter.Preserve entire life cycle. Predominantly, computational\nskills support procedures openness traceability, including\npreparation data code restricted unrestricted sharing.course, likely every core activity draw 3\ntypes technical skills.","code":""},{"path":"how.html","id":"foster-nontechnical-skills","chapter":"4 How","heading":"4.3 Foster nontechnical skills","text":"practice data science well keep constant change, \nenough focus technical skills knowledge. Technical skills\ncover know-answering good scientific questions rigorously\nusing data, technical skills limits can become obsolete \nmethods, tools, technology advance.Nontechnical skills (sometimes called “soft skills”) personality\ntraits, goals, motivations, preferences valued \napplied domain. example, collaboration communication call \ninterpersonal skills. addition, many sources (Davenport Patil (2012)) emphasize practice data science \npassionate, curious problem-solvers. pay special attention \ntraits support, even empower, learning data \nlife cycle, centered analysis subject scientific norms. \nwords, describe unpack traits flow love \nknowledge learning, followed traits support ethical\nconduct data science.","code":""},{"path":"how.html","id":"intellectual-character","chapter":"4 How","heading":"4.3.1 Intellectual character","text":"progressive culture data, fostering intellectual character can\ncultivate responsible learners inquirers better able keep\nfast-moving methods, tools, technology. Intellectual virtues\nflow love knowledge learning, aiming “cognitive goods”,\nlike truth understanding (King 2014; see also Costa Kallick 2008). data\nscience, practitioner seeks understanding mediated data \nlife cycle data. Intellectual virtues animate scientific practice\ngeneral data science particular. subsection draws heavily\nwork Jason Baehr, especially Baehr (Baehr 2013a; Baehr 2013b; Baehr 2015).Baehr (2015) describes 3 dimensions intellectual virtue: First, \nability skill specific virtue leading action. \ntrait curiosity, skill asking good questions. Second, \nmotivation commitment apply virtue. curiosity, \nmotivation ask good questions love knowledge \nlearning. Third, judgment sensitivity know \nexercise virtuous abilities skills. curiosity, sensitivity\nconcerns start, continue, pause, stop inquiry. addition,\nvirtue can seen mean vices—little good\nthing much good thing. little curiosity vice \nindifference, much curiosity vice obsession \nfixation.can identify several intellectual virtues examining \ndispositions associated stages inquiry approaching \nobjective: starting learn heading right direction, keeping\ninquiry track, dealing obstacles. stage \ninquiry described , list stage-related virtues use pipe\ncharacter (“|”) delimit virtue’s corresponding ability \nskill, motivation commitment, judgment sensitivity, vices\nrepresenting much little virtue.Start learning head right direction. intellectual\nvirtues relate start learning start inquiry ensure\nheads right direction: addition curiosity,\nintellectual autonomy ability think oneself, \nintellectual humility ability admit one’s limitations—\nknow don’t know.Curiosity: Ask good questions | learn | discerning \nstart, continue, pause, stop inquiry | mediating \nindifference fixation.Intellectual autonomy: Think oneself | achieve independent\nthought self-assuredness | discerning yield others \ndifferentiate others | mediating conformity \nradicalism.Intellectual humility: Admit one’s limitations | recognize\none able unable locate oneself context\nothers’ interests | discerning assert oneself stand\nback | mediating arrogance self-deprecation.Keep learning process track. starting inquiry, \nintellectual virtues assist learner keeping track:\nAttentiveness ability engage, look listen, \nnotice details. Carefulness ability spot avoid errors.\nThoroughness ability go deep order gain understanding\nexplain.Intellectual attentiveness: Look listen | remain alert \ndetails | discerning tune focus intently |\nmediating distractedness preoccupation.Intellectual carefulness: Avoid errors | assure control \nquality one’s output | discerning ease double\nquality control | mediating sloppiness \nperfectionism.Intellectual thoroughness: Go deep understand | ensure\nsufficiently complete coverage treatment | discerning fill\ngaps let well enough alone | mediating superficiality \nmeticulousness.Deal obstacles. Even track learning, one likely \nencounter obstacles. learner benefits intellectual virtues \nhelp work around obstacles: Open-mindedness helps think\noutside box confronted challenge solve. Courage helps\nbold take intellectual risks. Flexibility helps adapt \nneeded. Tenacity perseverance helps embrace struggle working\nchallenge.Open-mindedness: Think outside box | consider new \nunfamiliar ideas seek diversity inclusion | discerning \nideas dismiss entertain idea | mediating \nnarrow-mindedness gullibility.Intellectual courage: Take intellectual risks | allow bold\naction despite potential failure | discerning tolerate\nless potential failure | mediating cowardice \nfoolhardiness.Intellectual flexibility: Adapt needed | allow change,\nespecially improving outcomes | discerning much \nstand firm alter activity | mediating intransigence \nsuggestibility.Intellectual tenacity: Carry | continue toward learning\nobjective, even challenged | discerning persist \nstop trying | mediating fickleness stubbornness.Intellectual virtues can conflict . example, courage\ncan conflict humility drive take intellectual risk\nruns counter limitations one’s abilities (one’s reach\nexceeds one’s grasp). navigate conflicts, good learner \nthinker aided mediating virtue practical wisdom. \ntrait allows inquirer (phronimos, per Baehr (2013a)) grasp \nintellectual activity valuable attaining one’s goals. Recall\nBaehr (2015) identifies one dimension intellectual virtue \njudgment sensitivity exercise virtue.\nPractical wisdom undergirds dimension, allows good\nlearner thinker take suitable action intellectual virtues\nconflict. (See Turri et al. (2021) Baehr (2013a).)Even , good learner thinker, motivated apply\nintellectual virtues, still need develop abilities \njudgment connect motivation right action. Intellectual\nvirtues developed practicing critical reflection \nactions dispositions. get better courage \npracticing courage—taking intellectual risks learning \nconsequences. get better humility practicing humility—\nowning limitations shying away . also develop\ncultivate practical wisdom—avoid vice mediate conflicting\nvirtues—practice guidance seeing modeled \nothers. Curricula resources, including literature, computing\nresources, mentors, can help intentionally systematically\ncultivate intellectual virtues. return ideas section\nlearning data science community.Just associated core activity technical skills, can\nalso associate critical reflection process nontechnical skills.\nSetting expectations corresponds starting learning heading \nright direction, calls curiosity, autonomy, humility.\nCollecting information comparing expectations information\ncorresponds keeping learning process track: attentiveness,\ncarefulness, thoroughness. dealing matched mismatched\nexpectations information corresponds dealing obstacles:\nopen-mindedness, courage, flexibility, tenacity.Intellectual virtues, stage inquiry.","code":""},{"path":"how.html","id":"ethics-and-values","chapter":"4 How","heading":"4.3.2 Ethics and values","text":"intellectual virtues connect love knowledge learning \npractice asking answering questions, ethics values\npromote behaviors achieve goods, including trust, equity, \nfairness.seek protect personal privacy, balance privacy utility,\nspecific behaviors throughout life cycle data: posing\nquestions raise undue risk respondents; obtaining, using,\ncommunicating , sharing data ways limit risks privacy\nconfidentiality; interpreting communicating findings ways\nrespect rights welfare subjects analysis;\npromoting openness, transparency, aspects data utility\nmake overall process, methods, final products available \nscrutiny.considerations concerning ethics values practice \ndata science stem conduct research involving human subjects,\nconduct public health surveillance, scientific integrity, \npublic service. Many considerations pertain data, data\nsystems informatics, data analysis. go beyond privacy \nconfidentiality justifications gathering information; \nbalancing benefits harms, burden utility, access security;\nself-determination substantive engagement; justice; duties limit\ncollections use collected, responsibility avoid\nfabricating, falsifying, plagiarizing. duties covered\nextensively elsewhere often implemented regulation,\npolicy, checklists, forms guidance. (See, example,\nCDC's Office Public Health Ethics \nRegulations Privacy\nProgram.)progressive culture data, value data data help us\nlearn things world make informed choices \ninteract world. value innovation technology insofar\nhelp us continue expanding means good things\ndata, seek innovation technology ends \n. extensive set tools gives us broadest options \ngood things, remain open unfamiliar \nunconventional familiar conventional. Based values,\npractice pragmatic, principled pluralism exploring using\nwisely well methods can help achieve technical excellence\nlearn , , data. Principled pluralism allows honest\ndisagreement methods, results, interpretation.","code":""},{"path":"how.html","id":"foster-community-and-leadership","chapter":"4 How","heading":"4.4 Foster community and leadership","text":"Community leadership form essence culture progressive\nculture data—essential defer full discussion \nnext section (5). section, sketch community leadership\nenable practice data science along following dimensions:Learning. Community supports learning data, learning \ndata science, centering learners. Learning can follow\nformal curricula encouraged structured programs, \nsubstantial portions learning occur informal settings. Learners\nbenefit interactions peers mentors. Mentors benefit \nmeta-mentors. Advocates influence, guide, support \nlearning-oriented community.. Community supports practice profession data\nscience giving everyone wants good things data \nresources . Data science learner-practitioners basic \nintermediate data skills come discipline good things\ndata. Expert practitioners go deep data science methods \nguide practitioners proceed rigor stand behind work.\nManagers supervise practitioners experts, ensure \nresources direction need achieve good things \ndata. Lay advocates, persons literate value data, work \ncommunity practitioners, experts, managers help ensure\nsupportive resources enable practice data science.Staffing. Community creates ensures capacity data\nscience staffing career development available means\nrecruit, retain, organize, develop learners, doers, \nsupporters. includes identifying building data science\npotential among existing staff, finding using mechanisms bring\nlearners well federal nonfederal staff, \norganizing formal informal structures staff learn, ,\nmanage, support data science effectively.Leading. progressive culture data, leadership aims toward\nflows practical wisdom. Leadership part practice \ndata science, separate . Leaders include practitioners,\nexperts, managers, laypersons, regardless career stage,\njob title series, credential, location hierarchy (subject\nstructural constraints federal system).Within across dimensions, individual can carry \none role function. example, dimension, \npractitioner can serve expert manager. person\ncan also serve meta-mentor advocate learning dimension.\nnext section, expand roles functions align \ndimensions.","code":""},{"path":"who.html","id":"who","chapter":"5 Who","heading":"5 Who","text":"","code":""},{"path":"who.html","id":"who-gets-to-do-data-science","chapter":"5 Who","heading":"5.1 Who gets to do data science?","text":"Everyone wants good things data intellectual\nsupport , long proceed rigor stand behind \nwork. first formulated credo 2016. asked, “gets data\nscience?” express empowerment (ability) privilege (\nauthority). proclaiming one need expert \nstatistics computer science perform well working data. Indeed,\nnonstatisticians can, often , perform great work data.believe credo experience mentoring, coaching, \nadvising learners variety CDC CDC-adjacent programs, including\nfellowship student internship programs, undergraduates, masters \ndoctoral students, postgraduate learners. first years \nCSELS ADDS role, emphasized learning-oriented, empowering component \ndata science: “everyone wants good things data”. \nmentoring experience, learner’s specific analytic technical background \npoor predictor well , especially programs \ndon’t recruit specifically previous analytic technical education. \nexample, worked several physicians specific statistics\nbackground, went execute superb analyses, even winning awards. \ncase, proceeded rigor stood behind work. role \nmerely mentor; took challenges data science. Conversely,\nlearners apparent analytic background either shunned rigorous analysis\nfumbled badly. CDC programs can select prior technical analytic\nexperience, don’t believe CDC programs need .gets data science? can restate question echoing credo \nfollows: wants good things data, proceed rigor, stand\nbehind work? can restate question , echoing working\ndefinition data science: line tools ask answer good\nquestions rigorously using data? answer 3 versions \nquestion. Self-learning problem-solvers get data science: people\nconnect love knowledge self-learning solving problems, people\nask thoughtful questions, pay close attention details, honestly\nacknowledge don’t know, probe deeper meaning, persist \nface obstacles. (See also Baehr (2013b).)2016, felt energized tout empowering message focused learning\nrather specific disciplines. slowly realized message \nincomplete. situated self-learning problem-solvers learning-oriented\ncommunities mentors advocates, needed say learners,\nmentors, advocates , specific technical nontechnical skills fit\n, community operates beyond learning. mid-2016 \nmid-2019, primary formulation transmuted gets data science\nexpansive inclusive participates progressive culture\ndata. began acknowledging nonexperts good things data\noften need guidance experts empower achievements. Furthermore,\nnonexperts experts alike need support resources members\nprogressive culture data.also believe CDC substantial, untapped well potential among\nexisting staff good, better, things data. words, CDC\nachieve, make great strides toward, progressive culture data \nright attention direction regarding learning, , staffing, \nleading. seen CDC whole make moves, though pockets \nshow promise.gets data science? Echoing NIST, Office Personnel Management\n(Reinhold 2019) says, “Practitioners sufficient knowledge \nareas business needs, domain knowledge, analytical skills, software \nsystems engineering manage end--end data processes data life\ncycle. Overlapping skills including data analysis, analytical applications, big\ndata engineering, algorithms, domain expertise, statistics machine learning.\n[] use expertise one domains solve complex data\nproblems.” answer lacks poetry specifies details terms \nknowledge, skills, work activities. details useful creating\nstaffing strategies, occupational qualifications, position descriptions.Finally, leads progressive culture data? Everyone get .","code":""},{"path":"who.html","id":"learning-in-a-progressive-culture-for-data","chapter":"5 Who","heading":"5.2 Learning in a progressive culture for data","text":"2018, added following growing collection personal mottos:\n“Less training, learning.” meant culture \nexplicitly recognize support personal initiative self-direction \nways—view important ways—gaining knowledge experience\nsolving real problems, especially entering workforce. Community\nsupports learning data, learning data science, centering\nlearners. Learning can follow formal curricula encouraged \nstructured programs, substantial portions learning occur informal\nsettings, reading, self-guided learning, interaction peers.\nexperience, culture overemphasizes training risks undervaluing \nfull gamut ways learners learn.focus learning respects agency responsibility learner, \nmust take active role receiving instruction practicing\nhoning learned. focus learning opens way \nvarious models modes learning, including self-teaching reading,\ncrafty -line searching, independent tutorials, experimentation.\nSelf-guided experiential learners need guidance others, mentoring, \nhelp identifying filtering material can assist learning.\nLearning concerns individual development also better serving \nshared mission, example, asking better questions, working better \ndata sources structures, communicating rigorously clearly \nvariety audiences. Learning focus technical skills \nalso means exercise data acumen, good sense, judgment.Beyond developing skills among current staff, need agency culture \nprovides intellectual support everyone wants good things data,\nwhether already skills . already skills,\n’s matter supporting good practice, supporting continuing development,\nencouraging support others. lack skills, ’s \nmatter providing support oriented learning new skills \nadapting skills areas.","code":""},{"path":"who.html","id":"relational-learning","chapter":"5 Who","heading":"5.2.1 Relational learning","text":"start relationship learners—typically fellows,\nstudents, early-career scientists—mentors, since relationship\nformed initial impetus entire conception progressive culture \ndata.Mentors create supportive conditions guide scientists learn\ndata learn data. mentor responsible guiding technical\nskills encourage personalized direction self-learning, sometimes \nspecific skills managing relational databases, creating graphics \nsmooth binary outcomes, modeling seasonality, exploring categorical data\nusing mosaic plots.experience, experience important learning \nspecific subject-matter knowledge. typically guide learner clear\nthinking critical reflection particular methods. Mentors also\nmodel intellectual virtues. show example openly practice\ncuriosity, courage, humility. Mentors also create regular opportunities \nlearner practice intellectual virtues stimulating curiosity, rewarding\ncourage, fostering humility. ways, nontechnical skills \nfundamental scientific practice technical skills : learning \nlearn , , exercise judgment regarding level \neffort, intensity exploration, extent experimentation, making interesting\nmistakes. Practical wisdom matures part guidance part \nreflecting one’s lapses intellectual virtue. mentor can help \nlearner .context education, Baehr (2013b) explained educating \nintellectual character growth personal, involves thinking \nlearners persons whose basic beliefs, attitudes, feelings knowledge\nlearning also matter critically quality education; \nnecessarily social relational, personal change growth\noccur readily context trusting caring relationships; , \nreflective, involves reflecting discussing \nlearners value thinking learning, regularly pausing identify \nreflect significance learned. mentoring relationship\nresponds nurtures love interest thinking, learning, answering\ngood questions. “Intellectual virtues flow, desire praise \napproval, genuine interest thinking learning.”\n(Baehr 2015)mentor, often explain thought process learner, messy \nnonsensical thought process might . Thinking loud learner,\nusually idea whether ’m making sense, real honest. \nalso exercise vulnerability. turn, mentor must earn trust \nrespect learner, learner able take risks make\ninteresting mistakes thought processes.CDC needs better job finding supporting mentors informal \nformal ways. discussion staffing capacity data science,\npropose approaches articulating competencies accounting \nperformance.robust culture supported mentoring, mentoring relationships go \nseveral directions. started relationship mentor \nlearner. communities peers, learners can mentor \npersonal, relational, reflective ways mentors learners. \naddition, mentors benefit guidance wisdom experienced\nmentors, call “meta-mentoring”. Finally, advocates influence, guide,\nsupport learning-oriented community.Learners ask questions, solve problems, reflect critically process, \nimprove skills. take responsibility self-learning, seek\nmentorship, practice technical skills intellectual virtues. Learners\ntake risks make interesting mistakes, learn exercise\njudgment. Learners use data responsibility improve world. Learners\nparticipate community fellowships learning programs,\ncommunities practice, scientific workgroups, interest groups, user\ngroups. Statistical Machine Learning Community Practice \ncommunity learning data, example grass-roots network learners\nbrought together members scientific workgroups, user groups, \ngroups.Advocates influence practice profession data science, promote \nreward commitments data self-learning, remove needless barriers (e.g.,\ntechnology-related procedures), support instructive failures interesting\nmistakes, encourage practice data science, uphold \nprofess data science. Advocates include managers, decision-makers, associate\ndirectors, directors, others.","code":""},{"path":"who.html","id":"formal-curricula-and-structured-programs","chapter":"5 Who","heading":"5.2.2 Formal curricula and structured programs","text":"progressive culture data can promote systematic standardized\nlearning formal curricula technical skills nontechnical\nskills. Numerous vendors now offer courses wide variety \ncomputational data-analytic skills. CDC makes many available\nOCIO, CDC University, programs like Advanced Molecular Detection, \nsessions organized CDC workgroups user groups. addition endless\noptions courses technical skills, curricula also available \nnontechnical skills (e.g., Educating Intellectual\nVirtues), though readily\navailable.CDC rich, long, successful history structured, experiential\nlearning programs, including professionals outside CDC. \nrecently, programs intentionally explicitly addressed data\nscience. EIS program addressed analytic skills limited ways.\nInformatics prevention effectiveness programs specific, narrow\ntechnical areas focus. Participants programs regularly benefit \ncommunities mentors peers, also purposefully addressed\ndata science.recent developments demonstrate incremental shifts: EIS program \npiloted continues provide mentoring EIS fellows advanced analytic\nprojects. fellowship programs also piloted efforts create teams \nfellows different programs intentionally interdisciplinary work.\nRecent modernization initiatives sponsored fellows \nfocus data science. Finally, Data Science Upskilling (DSU) program\nlaunched 2019 dozen teams incumbent federal staff \nfellows, focusing primary project, -demand, online courses, \ncross-team activities 5 components data science: statistics, machine\nlearning, computing, visualization, ethics.DSU allows federal staff learners set aside time \ngo deep data methods new unfamiliar , well \ntime trial error. program predicated explicit organizational\nsupport, including supervisors, well structured leadership access\nexperts, learning resources, technical tools, fellow learners.\nParticipants refine existing skills learn new skills analytic methods,\nsoftware R, Python, Power BI—importantly, limited \nprior primary occupational series disciplines. generally learn \nestablish clearer boundaries motivating data science projects, develop\nworkable (preliminary) solutions, establish community practice. \nmethods tools used DSU new, though might \nunfamiliar uncommon within CDC’s general culture. program brings \noverarching purpose specific value learners programs \nfocusing specific, mission-oriented problems. thus establish, expand,\napply methods, tools, technology available CDC use rigorously.\nFurthermore, enrich teams’ ability adapt \nfast-changing contexts: newer questions, less familiar data sources, less\nfamiliar methods technology, comes close vision \nmotivation disposition progressive culture data.","code":""},{"path":"who.html","id":"doing","chapter":"5 Who","heading":"5.3 Doing in a progressive culture for data","text":"progressive culture data centers learning order empower \npractice profession data science. Community supports practice \nprofession data science ensuring everyone wants good things\ndata resources . account, see 4 primary roles \nculture: learner-practitioners (also call “learners doers”),\nexpert practitioners, managers, lay advocates. roles can change \ntime overlap roles articulated \nlearning-oriented roles (mentor, learner, advocate). roles capture \nessential distinctions primary practical needs culture \ngood things data.Learner-practitioners basic intermediate data skills come \ndiscipline, just computer science statistics, good things \ndata, mindful full life cycle data.seek good things datacome discipline, just computer science \nstatisticsachieve, work toward, data proficiency, building \nfundamentals work rigorously complex data \nmethodslearn continuously show modern tools methods\nsolve modern problemsmindful full life cycle dataExpert practitioners achieve data mastery go deep data science\nmethods provide intellectual foundation good practice.provide intellectual foundation good things\ndata, aiming scientific quality analytic\nrigormaster complex data structures methodsliterate advanced, contemporary methods complex\ndata structures methods, high-volume \nhigh-velocity data; analysis patterns predictions\nwell inferences; visual methodsinterpret, communicate, memorialize learning \ndatapractice personal proficiencyensure everyone wants good things \ndata, canset norms data-oriented practice learning\n, , dataenable, guide, correct, empower practitioners \nproceed rigor stand behind workmindful full life cycle dataManagers supervise learner-practitioners experts ensure \nresources direction need achieve good things \ndata, now future.data fluency, acumen, proficiencyhow assess scientific quality analytic rigor \ndata-oriented solutionshow allocate investments data-oriented learning \ntechnologyhow allocate data-oriented assignmentsfoster reward curiosity, invest learning (just\ntraining), encourage creativity interesting mistakeshold practitioners experts account producing\nknowledge learned , , dataadvocate means enable practitioners \nexperts continue increasing capability,\nefficiency, effectivenessLay advocates work community practitioners, experts, managers \npersons literate value data help learn things world.data fluency acumenhow assess basic quality data-oriented solutionshow allocate investments data-oriented learning \ntechnology","code":""},{"path":"who.html","id":"staffing-in-a-progressive-culture-for-data","chapter":"5 Who","heading":"5.4 Staffing in a progressive culture for data","text":"progressive culture build sustain capacity keep \nfast-moving methods, tools, technology? people brought ,\norganized, kept around?Harvard Business Review headlined data scientist “sexiest job \n21st Century” (Davenport Patil 2012). Fast Company called one \nbest 25 jobs America (Dishman 2016).","code":""},{"path":"who.html","id":"data-science-staff-should-be-cultivated-hired-and-outsourced","chapter":"5 Who","heading":"5.4.1 Data science staff should be cultivated, hired, and outsourced","text":"Amidst mixture excitement marketing hype data scientists,\n’s recurring question whether data scientists recruited \nhired outside cultivated inside.Data scientists hard find attract. … Data scientists rare\ncommodities. … data scientists —curate data, ask right\nquestions, build explanatory analytical models, implement models \nvarious applications—simply scaling pace demand.\n(Millis 2015)prominent data scientist Silicon Valley ... doesn’t hire basis \nstatistical analytical capabilities. … [] seeks skill set—\nsolid foundation math, statistics, probability, computer science—\ncertain habits mind. wants people feel business issues \nempathy customers. , says, builds --job\ntraining occasional course particular technology.\n(Davenport Patil 2012)believe indeed learn data science job. true data\nscientists know [specific technical skills] … self-learners\ncan catch quickly … focusing people call data\nscientists mistake. (Van Cauwenberghe 2015)3 quotations, sense data scientists hard come .\nFurthermore, since need keep fast-moving methods, tools, \ntechnology, need firm foundation technical nontechnical skills \nwell disposition self-sufficiency continuous learning.Federal workforce flexibilities afford rich variety staffing mechanisms \norganizational options achieving sustaining effective mix: career\ndevelopment among federal staff learners, recruiting new federal staff\nlearners, adding collaborators academia partners, \nacquiring data science services contracts. section provides \nbrief, opinionated summary narrowly focused considerations. organize\ndiscussion around 6 broad, mutually exclusive segments:Federal employees already staff, including civil service uniformed\nstaffFederal employees already staff, including civil service uniformed\nstaffTo--recruited federal employeesTo--recruited federal employeesFederal nonfederal staff learning programs, glossing \nnontrivial nuances distinguishing federal learners (e.g., fellows hired\nTitle 42) nonfederal learners (e.g., ORISE research participants)Federal nonfederal staff learning programs, glossing \nnontrivial nuances distinguishing federal learners (e.g., fellows hired\nTitle 42) nonfederal learners (e.g., ORISE research participants)Collaborators academia funded grant cooperative agreementCollaborators academia funded grant cooperative agreementResearch development contractors federally funded research \ndevelopment centers, university-affiliated research centers, national\nlaboratoriesResearch development contractors federally funded research \ndevelopment centers, university-affiliated research centers, national\nlaboratoriesCommercial vendorsCommercial vendorsFor ease presentation section, sidestep details \nignored practice. example, learning programs, mean\nstaffing mechanisms fellowships, coursework programs like Data\nScience Upskilling. addition, include academic collaborators \nIntergovernmental Personnel Act Special Government Employees along \ngrantees, even though IPA funding executed like contract (acquisition)\nrather grant (assistance) SGEs technically civil federal\nemployees.material section corresponds similar, expansive\ndiscussions HHS Data Council’s Data-Oriented Workforce Subcommittee\n(Gehrke et al. 2021; Wagner 2022). subcommittee’s reports\npresent rich, thoughtful, comprehensive detail staffing organizing \ndata science federal workforce. provided critical input \nsubcommittee, views present .","code":""},{"path":"who.html","id":"federal-employees","chapter":"5 Who","heading":"5.4.1.1 Federal employees","text":"federal government expanding options classifying developing\nfederal employees data science. Historically, occupational series \nscience, technology, engineering, mathematics (STEM) represented narrow\nworkable disciplines, including engineering (0801), operations research\n(1515), mathematics (1520), statistics (1529 1530), computer science (1550),\nextent information technology specialist (2210); \ncombined interdisciplinary positions, 0601/1530. \nscientific technical series social behavioral sciences (0101),\nmicrobiology (0400 group), health sciences (0600 group) used \npositions focus research analysis. Around 2016, wrote CDC’s first\nposition description (series 1530) explicitly included machine learning.2018, Office Personnel Management issued direct-hiring authority \nSTEM positions economics, biology, engineering, physical sciences, math\nfields. 2019, OPM released guidance adding parenthetical “(Data\nScientist)” titling several series (Reinhold 2019). Managers\nNational Center Injury Prevention Control developed set \nstandard “(Data Scientist)” position descriptions several series grades.2019, CDC hosted sequence Future Work (FoW) workshops develop data\nscience profiles. appreciated focused attention, perceived \napproach provide much latitude existing federal staff \nexperts data science influence shape direction effort. Data-oriented experts already workforce direct\nexperience inform needed good things data—like\nexisting supports motivators (interesting problems supervisory\nsupport) well persistent challenges (like barriers nimbly using -cost\ndata science software). FoW’s contract support staff say something \nways industry improves use data, lacked awareness \nwithin CDC’s culture working data. also perceived \napproach risked conflating informatics data science rather clarifying\ndistinctions . benefit side, FoW fleshed concept\ndata fluency minimum competency much federal workforce. \nschema progressive culture, managers laypersons \nbest support culture achieving least data fluency.Finally, late 2021, OPM issued new data science occupational series 1560.\naccompanying flysheet substantially emphasizes defining importance \nlife cycle data, covers job activities diffuse \nill-defined enough take special care use series effectively.\npreferred improving way federal agencies use existing\nseries, including flexibility titling combining series, \ndevelopment deserves taken seriously. Thus, CDC actively working \ndevelop qualifications, competencies, position descriptions, resources\nrecruiting hiring data scientists.Based experience learners, user groups, early-career\nprofessionals CDC, believe unrecognized untapped potential already\nexists among incumbent federal staff CDC far failed see \ncharacterize potential. realize latent capacity, need shift\nthinking traditional assessments existing skills traditional\nemphasis training, assessments aptitudes habits mind \nradically different take --job learning rewards self-learning \nnurturing networks peers mentors. least important, \nfinding employees learners experiences interests \nneed want order good things data, rather narrow\ntop-focus managers perceive—especially managers unfamiliar\nmotivations, commitments, prospects data science. makes\nlittle sense talk recruitment retention without examining\nmakes prospective practicing data science practitioners want order\njoin workforce stay .Tapping potential also calls culture shift among staff \ncan data science. can important, example, \nstatistician maintain professional identity discipline,\nstatisticians (computer scientists others) need see \npart , rather separate , intentional cross-disciplinary engagement.Turning hiring, CDC faces well known challenges competing sectors.\nAware limited flexibility enhance incentives prospective hires, \nnonfinancial incentives can CDC offer? Foremost, CDC’s unique mission public\nservice already draws employees many disciplines; , CDC appeals \nmany recruits’ personal values. Second, CDC cultivates truly progressive\nculture data—one rewards drive learn well drive \ncontribute—CDC becomes much attractive exactly kind \npeople can sustain enrich progressive culture. culture\nmust genuine, else attractiveness fade.Stepping back fine details series grade, whether federal data\nscience staff cultivated within hired outside, \nimportant operational considerations pertain competencies performance.\nCDC needs practitioners able data science, whether part \nduties. side benefit CDC efforts flesh series 1560,\nhuman resources staff developing richly varied set competencies,\nwork activities, proficiencies. supportive resources can \nshape series beyond new 1560. 1530 statistician adopt \nexpansive data-analytic competency enriched competency machine\nlearning artificial intelligence. human resource concepts can\nadapted performance elements statements, everyone\ndata science can accountable rewarded . addition\ncompetencies performance elements arise series 1560, CDC \nalso develop competencies skills associated intellectual virtues.\nSkills competencies oriented learning, practical judgment, mentoring\nalso help differentiate proficiency grade within series \n() apply scientific series.","code":""},{"path":"who.html","id":"fellows-and-other-learners","chapter":"5 Who","heading":"5.4.1.2 Fellows and other learners","text":"CDC manages partners dozens structured learning\nprograms dozens topics, open\npersons variety educational backgrounds. Fellows stimulate, \ndemonstrate CDC’s commitment , vital culture learning. CDC sometimes\nhires fellows federal staff, often intentional career path. Although\nCDC fellows contribute CDC’s product, primary purpose learn, \naugment staff.CDC fellows focus largely good things data. fellows\nget good things data, whether focus data .believe CDC commit helping CDC programs develop data science\ncapacity focus fellows, follow-intention \nmembers learner’s program unit can also develop data literacy \ncompetency. Early drafts 2018 Public Health Data Strategy called \nready response unit data scientists work CDC programs \nneeded. unit created, recommended focus \nworking fellows, requesting CDC program develop \ncapacity address data-oriented need rather relying outside staff\ntake care move . (side note, Center Forecasting \nOutbreak Analytics largely goes opposite direction recommendation,\ninvesting substantial data science resources center rather \ndistributing among CDC programs.)fellows need support peers mentors. end, CDC \nfoster mentoring supported competency, accountability reward\nperformance appraisal incentives. CDC , however,\noverinstitutionalize mentoring, role needs latitude \nflexibility fostering technical nontechnical skills.","code":""},{"path":"who.html","id":"nonfederal-collaborators","chapter":"5 Who","heading":"5.4.1.3 Nonfederal collaborators","text":"addition federal employees learners, nonfederal collaborators serve\nCDC’s data science needs, joint research projects \nacademic public health partners, research development\norganizations, commercial vendors. CDC often engages academic\npublic health collaborators grants cooperative agreements \n-called mobility agreement Intergovernmental Personnel Act\n(administered like contract grant). Research \ndevelopment organizations include federally funded research development\ncenters (FFRDCs, operated MITRE Corporation RAND\nCorporation), university-affiliated research centers (UARCs, Georgia\nTech Research Institute Applied Physics Laboratory Johns Hopkins\nUniversity), national laboratories (Oak Ridge National Laboratory\nSandia National Laboratories). Finally, commercial vendors include vast\ncollection entities bid sell proprietary services CDC \nFederal Acquisition Regulation.outside contributors can especially help filling gaps CDC’s \ncapacity data science activities varying discipline, skill, scale \nCDC can’t address . ’s important CDC, advocates \nmanagers, strive toward building capacity among CDC’s federal staff \navoid assuming outside collaborators can particular thing (\nforms text image analysis). ’ve argued elsewhere \nessay, CDC’s federal staff learners likely substantial, unrecognized\ncapacity extending CDC’s data science capabilities unrealized\ndirections. mistake outsource based faulty assumption.Many needs exceed CDC’s current capacity. necessary turn \nnonfederal collaborators, becomes especially important enough\nexpertise among CDC’s federal staff (bare minimum among trusted\nnonfederal partners) ensure contributions nonfederal collaborators\nmeet intended need. know ’re getting something useful, \nneed, collaborators? observed one project \nnonfederal collaborator—sometimes academic, sometimes\ncommercial—supplied deliverable home CDC program unable \nevaluate. instances, greater data science expertise within CDC\nprogram, another service community within CDC, helped\nensure proposed deliverables worth investment \nactual deliverables met need.","code":""},{"path":"who.html","id":"staff-organized","chapter":"5 Who","heading":"5.4.2 Data science staff should be organized to do data science","text":"","code":""},{"path":"who.html","id":"organizing-data-science-capacity","chapter":"5 Who","heading":"5.4.2.1 Organizing data science capacity","text":"described previous sections, progressive culture data needs data\nscience learner-practitioners (variety disciplines), expert\npractitioners (specifically data science disciplines), managers, lay\nadvocates. discussion focuses experts incomplete \nshort-sighted. everyone needs data scientist empowered \ngood held high standard. everyone needs held \nhigh standard.analysts data scientists integrated staff \ndisciplines set apart? question reality cut ways:\nstatisticians data staff often set apart, often prefer \nway. largely remote, post-Covid workplace configuration, \norganizational question comes 2 main characteristics can think\nwithin : data staff placed units \nhomogenous mixed collaborating staff disciplines? connected\ndata staff across distinct units? ’ve seen version \nconfiguration. idea grouping data scientists together seems like wise\nway manage limited resources, experience, fosters notion\ndata scientists separate. CDC’s Futures Initiative \nearly aughts, talk putting statisticians together one\ncenter. made harder work analysts \nconstrained development statisticians. think \neffective -around configuration mix data scientists \nprofessionals data scientists nearby data\nscience practitioners division, say, regularly interact \nwork problems together learn.","code":""},{"path":"who.html","id":"assessing-data-science-capacity","chapter":"5 Who","heading":"5.4.2.2 Assessing data science capacity","text":"CDC’s ability agency data science depends cultural\ncomponents listed : intentional cultivation learners well\nconstructive support direction data science practitioners experts\nrespects also appeals know-drive—\ntechnical skill nontechnical skills. assessment data\nscience capacity needs include, go beyond, characterizing aggregate\nset technical nontechnical skills. important also discern\npeople good things data need want \norder continue improve. Let’s break ideas focusing\npeople data science (practitioners experts) people \ndirectly empower, enable, support (managers). \nfederal system, also need distinguish federal staff, (nonfederal)\nlearners, nonfederal staff. Finally, want characterize\nindividual data science competencies well unit-level competencies \nincreasing levels aggregation, teams, branches (collections \nteams), .staff data science, want know proficiency aptitude\ntechnical skills data analysis computation apply across \nlife cycle data. experience, effective way discern\ntechnical nontechnical skills aptitude experts see skills\naction, either prospectively retrospectively: well can \npractitioner frame problem? Work kind data address problem?\nArrange, explore, analyze data using suitable tools? Correctly describe\ncritique analysis? Demonstrate critical reflection throughout? Keep \nactivity directed toward ultimate goal deal obstacles acting \ntraits curiosity, attentiveness, perseverance, open-mindedness, \ncreativity? addition broad set competencies, also want know\nparticular strengths, example, programming Python deep\nlearning time series, well areas warrant learning order \naddress intended data science tasks. one staff person needs master \ntechnical skills, sufficient acumen discern \nskills apply .staff supervise data science practitioners lead projects apply\ndata science, need assess edify data fluency, sufficient \nguide empower practitioners experts. Data fluency includes ability\nunderstand components life cycle data, components\nrelate , skills core activity calls , \nintellectual traits practices support critical reflection \nadaptation throughout life cycle. Managers , need ,\ndata science practitioners experts. manager lacks expertise, \nneed humility wisdom turn experts. Furthermore, managers\ndemonstrate skills needed foster learning mentoring.staff enable data science practice manage \npractice , information technologists cloud engineers. \nstaff, also need assess edify data fluency \nunderstanding life cycle data, centered analysis.Data science interdisciplinary. ensure domain knowledge addition \ncomputational data-analytic skills, need account combined set\nskills knowledge groups staff roll teams \naggregated units. need consider additional nontechnical skills \ncollaboration negotiation. considering collection staff \njoint mission, specific strengths, weaknesses, gaps \ncollective ability prepare, conduct, communicate analysis? \nspecial strength notable weakness areas affect ability \nmeet mission, detailed knowledge longitudinal claims data \ntime series methods? Assessment larger units especially call \nevaluative expertise outside unit, practitioners managers might\nable identify gaps.capacity assessment extends beyond individual collective skills \ntraits, however. incumbent staff think need order \ndata science well keep better? incumbent staff want \norder data science well keep better? Taking staff\ninterests seriously can nurture morale foster staff retention, also\nrecognizes staff often experts supporting bolstering \ncapacity. Just modernization pay due heed early-career\nprofessionals (epitome modern), world-class analytics pay due\nheed data science practitioners experts (epitome data-savvy), \nassessment data science capacity pay due heed staff \nactually things data. yet staff often overlooked \nintentionally directly engaged. Enlightened organizations often\nconduct exit interviews departing staff, part -action\nanalysis counterfactual: Now ’re leaving, conditions\nmight stayed? progressive culture data, practicing staff \ncontinuously seen partners, even experts, knowing unit can\nbest function keep fast-moving methods, tools, technology. \nculture, supervisors governance, continually engage\ndata-oriented practitioners proactively throughout tenure, empower\n, facilitate ongoing achievement, assure forward-looking resources,\ndirect efforts, hold account.","code":""},{"path":"who.html","id":"shaping-and-developing-data-science-capacity","chapter":"5 Who","heading":"5.4.2.3 Shaping and developing data science capacity","text":"Assessment lets us know little bit prepared \nmove directions want go. shape develop\ncapacity good things data? section outlines way \nstructure mission focus data science practice using 3 organizing\nrubrics predicated concepts presented earlier essay. rubrics\ntranslate organizing principles, lead specific practices.3 rubrics encompass (1) core activities practice data science,\n(2) prepositional calculus learning data, (3) primary \nfluid commitment specific topics services within unit’s mission.Rubric 1: Core activities practice data science. Data science\nintentionally connects core data science activities across life cycle \ndata, explained , together critical reflection core\nactivity.Rubric 2: Modes learning data. use data learn \nworld least 3 ways:Learn data, understand kinds questions might used \nanswer.Learn data, understand kinds questions might used \nanswer.Learn data, support answering questions put data.Learn data, support answering questions put data.Learn data, using data develop, explore, evaluate methods.Learn data, using data develop, explore, evaluate methods.prepositional calculus distinguishes assessing quality utility \nmaking inferences, turn distinguished focus methods\nlearning data.Rubric 3: Topical goods services. third rubric distinguishes \ngoods services delivered result engaging life cycle data.\nrubric, technical assistance collaborating partners \nessential service, developing methods ensuring data validity,\nevaluating case definitions, collaborative analysis population health.translate 3 rubrics organizing principles linking data\nscience activities.Rubric 1 → Principle 1. Link data science activities 1 core activities practice data science, context awareness core activities. team’s primary skills products organized around performing core activities, explicit notice scientific business question interest, source(s) transformation data, .Rubric 2 → Principle 2. Link data science activities 1 learning prepositions. purpose given activity understand structure attributes data source (learn ), make claims world trends asthma (learn ), get better carrying one purposes (learn )?Rubric 3 → Principle 3. Identify data science activities subject-matter inquiry, service, . Establish value priority purposes.Bringing together, data science capacity, skills support \nexpand capacity, linked directly priority tasks interests,\nturn tied core activities, “prepositional calculus”, inquiry\nvs service.Finally, identify put principles practice, following\nexamples:Consider team focuses primarily applying data science practice\nsyndromic surveillance. team carries tasks primarily related data\nengineering (learning data) supporting routine analysis \nemergency department data (learning data) surveilling opioid overdose,\nhurricane-related morbidity, heat-related illness, Covid-19, \nconditions public health interest. Although team’s work covers \ncore activities data science, focus primarily activities\nconcerning obtaining, exploring, analyzing data.Example 1 (). Among list proposed actual activities directed \nassessing assuring data quality utility, establish relative priorities\ncontingencies. activities include least following:Develop, automate, routinize, integrate measures health data\nfeeds, turn include characteristics completeness,\ntimeliness, conformance standards, fitness purpose; products\ninclude regular reports, -demand reports, summary dashboards.Develop, automate, routinize, integrate measures health data\nfeeds, turn include characteristics completeness,\ntimeliness, conformance standards, fitness purpose; products\ninclude regular reports, -demand reports, summary dashboards.Assess value limitations data content, demographic data \nreceived imputed.Assess value limitations data content, demographic data \nreceived imputed.Assess mechanics quality auxiliary data sources, including laboratory\nvital records.Assess mechanics quality auxiliary data sources, including laboratory\nvital records.Assess mechanics quality using 1 data source ecological\nanalysis, merging ZIP Code county level, aggregating\npost-fusion analytic results.Assess mechanics quality using 1 data source ecological\nanalysis, merging ZIP Code county level, aggregating\npost-fusion analytic results.Example 2 (). Among list proposed actual activities directed \naddressing specific, descriptive public health inquiry, establish relative\npriorities contingencies. activities include least following:Measure coverage representativeness methods results pass\npeer review.Measure coverage representativeness methods results pass\npeer review.Characterize persons included data sources, demographic (inferred)\nclinical factors.Characterize persons included data sources, demographic (inferred)\nclinical factors.Develop evaluate methods monitoring specific conditions, integrating\nexternal knowledge epidemiology conditions, detect\ntemporal anomalies way balances utility automated signals\neffort attend signals.Develop evaluate methods monitoring specific conditions, integrating\nexternal knowledge epidemiology conditions, detect\ntemporal anomalies way balances utility automated signals\neffort attend signals.Example 3 ().Document methods processing learning data sufficient \nmotivate independent re-implementation, interest transparency,\nreproducibility, intellectual credit.Document methods processing learning data sufficient \nmotivate independent re-implementation, interest transparency,\nreproducibility, intellectual credit.Advance ability process use data multiple sources.Advance ability process use data multiple sources.Advance ability develop data queries focus conditions \ninterest, going beyond matching substrings including machine-assisted\nrecord retrieval semantic analysis.Advance ability develop data queries focus conditions \ninterest, going beyond matching substrings including machine-assisted\nrecord retrieval semantic analysis.Advance ability incorporate temporal spatial information \ndetecting anomalies, focused specific conditions jurisdictions \ninterest.Advance ability incorporate temporal spatial information \ndetecting anomalies, focused specific conditions jurisdictions \ninterest.framework shaping developing data science capacity \nindependently invoke learning, learning essential defining\ncharacteristic progressive culture data. Rather, framework orients\nlearning toward rubrics, principles, practices data science,\nprepare data science . truly progressive culture,\nlearning specifically oriented product service can still\nserve essential good, prepares mind see possibility ,\none hopes, keep . Louis Pasteur said, “field observation,\nchance favors prepared mind.” (Pasteur Vallery-Radot)","code":""},{"path":"who.html","id":"leading-in-a-progressive-culture-for-data","chapter":"5 Who","heading":"5.5 Leading in a progressive culture for data","text":"Data science practitioners experts—learners doers—lead CDC\nATSDR modern era learning advocacy. progressive\nculture data, leadership part practice data science, \nseparate . Leaders include practitioners, experts, managers, \nlaypersons, regardless career stage, job title series, credential,\nlocation hierarchy. Practitioners experts must\nplay prominent, visible role creating leading progressive culture \ndata public health. professionals engage directly data, \nensure agency adopts, masters, promotes appropriately diverse\nset tools mindsets using data solve problems showing \nlearn data data empowering others .\nLeadership continually shapes sustains culture good data practice. \ncommunity, need advocate ensure interests needs \nfolded modernization initiatives agency becomes better tuned \nmeeting modern mission. learners doers see leadership separate \npractice data science, risk leaving .invest take pride personal technical excellence \ngood things data—construct, analyze, interpret models public\nhealth administrative outcomes. lead, though, need go \ntechnical excellence.emphasize learning data—unlocking meaning analysis. \nneed practical solutions-oriented public health . need\nrigorous, ensure data-analytic practices hold scrutiny,\neven ’s honest disagreement methods conclusions.principled pluralists methodology. see misapprehension \nimputation methods (“making data”), Bayesian methods (“subjective”), \nmachine learning (“black box”, “data dredging”). methods \ncan help us learn data, tools used wisely well.\nlargely Leo Breiman saying 2001 (Breiman 2001).promote praise good data-analytic practice, regardless job\ntitle, credentials, occupational series. Everyone wants good things\ndata intellectual support , long proceed\nrigor stand behind work. true sociologists \nmicrobiologists epidemiologists statisticians.provide leadership integrate data science \ninterdisciplinary efforts put data science equal footing \nspecialties. need able serve integral part team \ncollaborators backgrounds disciplines, apply translate\nrigorous data science concepts benefit collaborating scientists, \nexplore respect rigorous application concepts domains\npart collaborative undertakings. must learn practice methods \ninterpreting complex concepts nonspecialists, without unduly sacrificing\nrigor.said, experts data science foundation good practice \npractitioners, helping use data-analytic tools wisely well. \nprogressive culture data, leadership aims toward flows practical\nwisdom.hold fast solid norms learn data basis \nhigh-consequence decisions. Covid-19 pandemic time high\npressure, fast movement, substantial uncertainty, intense collaboration, \nrapid turnover. can tempting, circumstances, cut corners \nrigor—try get done faster make concessions quality. \nopposite needed: times like , Ebola, EVALI, \nhigh-consequence events, integrity important ever. Data science\npractitioners varied expertise shown can achieve high\nspeed high quality.lead every level. Front-line analysts lead showing modern\ntools methods help solve modern problems. Team leaders branch chiefs\nlead fostering rewarding curiosity, investing learning (just\ntraining), encouraging interesting mistakes come innovation.\nDivision center leaders associate directors help ensure \ninfrastructure—people, processes, technology—can support modern \nfuture tools methods. , specialize methodology\nanalysis lead wherever , everyone wants good\nthings data, can.","code":""},{"path":"redux.html","id":"redux","chapter":"6 Redux: Who, how, what, and why","heading":"6 Redux: Who, how, what, and why","text":"written ways CDC organizations \nbetter support culture good things data, especially \nview fast-moving methods, tools, technology. CDC, \nshared mission, commitment public service, intense,\npragmatic need draw expertise across disciplines multifaceted\nteams. surely hire great talent. also need \ntend staff already board.data generation, must foster technical skills mastery\ntechnique allows scientists extract information data; \nmust foster intellectual virtues, including practical wisdom, guide\ninquiry self-learning, enable scientists ask good\nquestions line tools answer questions rigorously \ndata; , must foster culture mentoring, peer support, \nadvocacy community practice empowers data science learners\ndoers keep fast-moving methods, tools, technology.: Everyone wants good things data get \nmake effort, long rigorous accountable.: individual level, data science calls technical\nskills computation data analysis nontechnical skills \nkeep inquiry directed toward learning data deal \nobstacles. collective level, calls progressive culture\nsupports putting skills use good things \ndata.: Data science studies learn data combining\nanalytic, computational, subject-matter methods connect \nwhole life cycle data, subject norms scientific quality \nanalytic rigor.: Foremost, data science learning data. Data\nscience helps us keep fast-moving methods, tools, \ntechnology learning data structures, sizes, shapes,\nspeeds.progressive culture remains rooted history continues learn\nold data new ways, anticipates future handles\nevolving demands. Cultivating progressive data culture present\nbest position field public health ever ready learn\nact data.","code":""},{"path":"i-get-to-do-data-science.html","id":"i-get-to-do-data-science","chapter":"7 I get to do data science","heading":"7 I get to do data science","text":"gets data science? !","code":""},{"path":"i-get-to-do-data-science.html","id":"how-i-think-about-data-science","chapter":"7 I get to do data science","heading":"7.1 How I think about data science","text":"January 2015, started CSELS CDC’s first, (least 7\nyears) , Associate Director Data Science (ADDS). NIH ADDS\ntime, CDC centers informatics statistics\nleads, now data science leads. title ADDS remained\nunique within CDC. stepped role 15 years becoming\nCDC employee 30 years first started working \ndata, statistics, computing. role CSELS ADDS, tried \nmake sense nonsense term “data science”, thinking \ndata science , matters CDC, \nimportantly CDC can public health better data better.\nEarly , favorite framing became definitional “\ndata science?” cultural “gets data science?”personal values motivated pursue technical excellence \noffer skills public service. entered public health \nwanted use rigorous methods help better human condition. \nmethodologist, trained math, statistics, philosophy, \nsmattering disciplines. like figure one can\nmeasure count observed quantify uncertainty \nremains beyond direct observation. culture perpetuates notion\n, inevitable march dispassionate science, humanity \ntake upper hand threatens saddens us. \nscientist resolve apparent discordance values \ncultural myth dispassionate objectivity? start acknowledging\ntools power scientific inquiry, respect role \ndevelop knowledge world. Values motivate shape\nscientific endeavors, passion can fuel scientific pursuits.\nNone us shrink apologize commitment \nmission public health. stories data necessarily express\nperspectives values; commit portraying defending\nworldviews.mentoring experience single greatest influence think\ntalk values can motivate shape data science, \nwell skills undergird data science practice. Since early\n2000, ’ve pleasure mentoring dozens early-career\nscientists—post-doctoral fellows Epidemic Intelligence Service,\nPrevention Effectiveness, Public Health Informatics, Oak Ridge\nInstitute Science Education (ORISE); undergraduate, master’s,\ndoctoral students; budding scholars professionals public\nhealth, medicine, philosophy, physics, mathematics. \nrelationships, poured bit respect managing\ndata, coaxing meaning data, delighting discovery \ndata, sharing stories data colleagues. Every one \nmentoring relationships changed data scientist \nreinforced belief learners believe.came believe 2 things practice profession data\nscience time CDC: (1) Everyone practices data science\nintellectual support rigorously, whether \nstatistician, epidemiologist, philosopher, brand \nscholar. Rigorous practice entails standing behind methods \nconclusions, can intimidating duty reaching beyond \nexpertise. (2) Everyone commits data science \nprofession accept intellectual responsibility contribute\nexpertise, collaborating leading scientists \ndisciplines. commit communicating clearly\nshare specialty don’t \nrespect ways specialty bolsters advances public health\nresearch practice.","code":""},{"path":"i-get-to-do-data-science.html","id":"my-personal-history-with-data-science","chapter":"7 I get to do data science","heading":"7.2 My personal history with data science","text":"’ve practicing professing data science one way another \nlong time, typically title statistician mathematical\nstatistician methodologist. 5 years old first grade, \nthought might want mathematician (artist \nbasketball player). sixth grade, got play Apple II, \nBASIC programming 5.25-inch floppy diskettes. \nundergraduate, helped teach obscure powerful programming\nlanguage APL (literally “Programming Language”) high school\nstudents. earned Bachelor Arts degree mathematics 1991 \nDoctor Philosophy degree statistics 1997.late 1997, 2 months filing dissertation, started\nCDC contractor Division Reproductive Health (DRH). \nbecame federal employee early 2000, continuing work DRH,\nmostly cohorts clinical trials, late 2004. spent\n3 years overseeing CDC’s institutional review boards thinking\nconnection justify research risk \nlearn data.served mid-2007 early 2015 Division \nTuberculosis Elimination (DTBE), working largely clinical trials \ncreative rigorous ways get better finding TB stop TB. \nDTBE, became self-appointed evangelist R statistical\ncomputing environment. 2012, articulated vision leadership \nmathematical sciences, included skills specifically technical\nexcellence clear communication—seeds belief \nleadership progressive culture data. March 2014, spoke \n“Scrappy Little Division Cares Lot Data: Vision \nData Sciences DTBE”. presentation included first use \ndefinition phrase “data science[s]”, particular attention\n“data science tasks: end end”, later called data life cycle.August 2015, shortly started CSELS ADDS, brainstormed\ndozens potential topics internal CDC blog explain \npromote data science, called “expression(data, science)”. wrote \nblog title fictitious programming language, monospace\nfont : \"expression(data, science)\". blog never really\nhappened. essay revives many topics brainstormed.November December 2015, presented \"Art Data Science:\nIntense Pragmatism Data Service Public Health\" \nEIS fall course. told story data science real-life\nexperiences 9 EIS fellows mentored. Although none \nfellows background specifically focused data analysis, many\nachieved great things data, others made interesting\nmistakes worth learning .May 2016, 14 months tenure CSELS ADDS, delivered CSELS\nscience seminar entitled “Data Science Data Wisdom: Cultivating \nData Generation” (pun \"generating data\"; maybe let \npuns), laid cultural components support \npractice data science. presentation evolved past\nyears become “Gets Data Science? Progressive Culture\nData Public Health”, placing data science context \nrelated distinct disciplines emphasizing data science\ndata science.latter days CSELS, turned attention largely machine\nlearning (ML) artificial intelligence (AI). regard ML \nextending set data-analytic tools available us, \nuse tools help us learn things \nworld—including potentially better ways public health\nsurveillance adapt flexible powerful ways find disease \nimprove health. ML, scalable applications AI, \nmysterious intimidating, tools regarded \nmagical familiar methods. Moreover, subject\ncritical reflection norms methods \nscientific inquiry. Current agency discussion potential ML\nAI risks focusing narrowly technology enough \nlearning data ways aim scientific quality rigor, \ndiscussed length sections 3.1 3.2 : posing\nquestions social value scientific validity ensuring \nconclusions traceable defensible, reasoning coherent,\nwhole process neutral, subject minimal subjective\nbias, rigorous, transparent, reproducible, . expand \nML AI section 8.","code":""},{"path":"i-get-to-do-data-science.html","id":"why-a-progressive-culture","chapter":"7 I get to do data science","heading":"7.3 Why a progressive culture?","text":"end 2016, CSELS ADDS almost 2 years,\nCDC's Surveillance Strategy successfully led demonstrable\nimprovements technology mortality, case-based surveillance,\nsyndromic surveillance, laboratory-based surveillance. Early\nformative efforts nascent Public Health Data Strategy 2018\ntapped dozens midcareer senior leaders shape next-phase\nmodernization. early days, lodged 2 substantive concerns:\n(1) Regarding data, staff work directly public health data\njoin co-leading nascent data strategy know\nfirst-hand challenges getting things done \ndata. (2) Regarding modernization, early-career staff also join\nco-leading modernization effort, likely \nessentially modern take data progress mid- \nlate-career leaders alone. August 2018, nominated “data science\nbreakfast club”—interdisciplinary collection dozen\nearly-career data science practitioners—discuss experiences\ndata science CDC CDC effectively develop data\nscience-savvy workforce. early 2019, neither concern data\nleadership modernization leadership gained appreciable traction,\nbreakfast club never convened. told “movement\"\nopen early-career data-involved staff, became clear\nmovement engage intentionally terms,\nco-leadership.strategy also struggled describe important \ndata better. emerging federal data strategy acknowledged \nimportance data asset. federal level agency\nlevel connected asset informed decision-making action. \nneither federal level agency level explicitly articulated \nsense data asset way data inform\ndecisions action. developed shared metaphor \nconceiving data treasure, coming acknowledge \nlargely hoarding treasure, cave. Like \ntreasure cave, data asset value, \nrealize value use spend rather store \ndata. Data value use data learn things \nworld things learn, including limited \nmaking decisions taking action. Data value use\nbuild things, like artificial intelligence tools, promise\nhelp us interact world efficiently effectively.became disheartened perceived regressive blinders.\nDespite pessimism, still believed intentions \nemerging strategy largely sound. challenged invert\npessimism asked, \"take CDC \nprogressive?\" 3 months later, drafted manifesto \nprogressive culture data public health, appended essay \nappendx ().2019, Public Health Data Strategy merged concurrently\nemerging Information Technology Modernization Strategy become \nPublic Health Modernization Initiative eventually Data\nModernization Initiative (DMI). August 2019, Surveillance Data\nPlatform wrapping work, presentation merged\nmodernization initiative enumerated 5 pillars modernization\nstrategy. Despite strategy’s stated intent develop “world-class\nanalytics”, nothing pillars addressed role analysis. \npointed , told implicit 5 pillars. \nvalue explicitly stated risks getting ignored. DMI came\ninitial political success form $50 million appropriation\nseed effort, fleeting moments Covid-19 pandemic pushed\nmodernization efforts funding overdrive. DMI concurrent\ninvestments prepared public health sector advance \nrapidly response pandemic ever expected. Nonetheless, DMI\nremained slow engage data practitioners early-career\nprofessionals leaders data revolution. Thus, manifesto\nstill complements DMI vision realizing value data \nasset culture centered roles data practitioners \nexperts, learners doers.manifesto now organizing principle essay. \nmanifesto, state, “progressive culture remains rooted history \ncontinues learn old data new ways.” collection \nrooted personal history.","code":""},{"path":"ml-ai.html","id":"ml-ai","chapter":"8 Machine learning and artificial intelligence","heading":"8 Machine learning and artificial intelligence","text":"CDC think machine learning (ML) collection data-analytic\nmethods (decades old) akin statistical methods. collection\nmethods extends set tools extracting information \ndata putting extracted information use, typically finding\npatterns data guessing likely output based set inputs.\nArtificial intelligence (AI), current practice, applies ML \ndata-analytic methods automate assist various tasks, especially\nrepetitive tasks. Indeed, AI follows largely applications \nML write pair “ML/AI” rather opposite: ML leads \ngrounds AI.Like data-analytic methods, ML methods used critical\nreflection: well model perform new data? well hold \ndifferent assumptions? perform consistent norms like\nfairness? application methods, AI subject \ncritical reflection norms.ML AI can simple complex, don’t mysterious. CDC\nuse wherever help CDC achieve mission better. CDC \n, however, use tools just sake , just satisfy \nconsultant’s recommendation, just appear modern.following discussion proposes demystify ML AI establishing\ncontext: ML/AI fit familiar, related concepts; \nML/AI fit related data-oriented methods; ML/AI fit history;\nML/AI might fit data-supportive organization; ML/AI \nalready practiced CDC/ATSDR.","code":""},{"path":"ml-ai.html","id":"context-what-is-familiar-or-known","chapter":"8 Machine learning and artificial intelligence","heading":"8.1 Context: what is familiar or known","text":"People direct experience ML AI especially conceive ML\nAI many ways don’t relate closely CDC might \n. example, heard sincerely posited ML \nrobots—literally, machines learning. machine learning approaches \nsupport robots, ’s common important meaning CDC’s\npurposes.ML described answering question, “can computers learn \nsolve problems without explicitly programmed?” (Koza et al. 1996) \ndon’t find formulation especially useful people aren’t already\nfamiliar idea. Let’s rephrase question “can computers look\nexamples figure patterns can applied new data?” \nexamples computers look data, “figure patterns” means \nuse algorithms develop model representation patterns. \nwords, ML collection data-analytic methods, typically used \nfinding patterns data guessing likely output based set inputs.Finding patterns data involve putting counties groups \ndemographically similar grouping tweets common topic.\nPattern-finding tasks, called unsupervised learning, include methods \ncluster analysis topic modeling.Finding patterns data involve putting counties groups \ndemographically similar grouping tweets common topic.\nPattern-finding tasks, called unsupervised learning, include methods \ncluster analysis topic modeling.Guessing likely output based set inputs also known \nprediction; entail best guess whether child meets \nsurveillance case definition autism given just words \neducational psychological evaluations. Output-oriented tasks, called\nsupervised learning, include methods regression classification.Guessing likely output based set inputs also known \nprediction; entail best guess whether child meets \nsurveillance case definition autism given just words \neducational psychological evaluations. Output-oriented tasks, called\nsupervised learning, include methods regression classification.publications apply machine learning public health issues,\nclassification appeared far commonly tasks, often \napplication separating cases noncases.initial note word “prediction” previous paragraph: \ncontext described , prediction focuses relating outcome—\npredicted value—corresponding given inputs, typically called “features”. \ncontrast everyday use, word “prediction” context might \nmight anything future. autism example , \nchild’s current case status predicted existing evaluations. \nanother example, model constructed predict receive \nParkinson’s disease diagnosis given past claims history; example\nincludes time component sense future, even example,\nmodel developed past data continuously evaluated future\naccumulating data.Since ML focuses using data tasks, thought \nprincipally analytic application, subject scientific norms \nsimilar norms applied empirical, analytic approaches, like\nstatistics causal inference. (See section 4.2.)predominant current practice, AI application ML automate \nassist recurring tasks, especially scaling repetitive tasks, \nassessing patient’s possible case status given electronic health record.\nAI thought principally application technology, \nunderlying ML still subject scientific norms data analysis.summary, can think ML (approximately) data-analytic methods \npractices AI results data-analytic methods practices\ndeployed applications automate assist recurring tasks, especially\nrepeated large scale.","code":""},{"path":"ml-ai.html","id":"context-methodology","chapter":"8 Machine learning and artificial intelligence","heading":"8.2 Context: methodology","text":"","code":""},{"path":"ml-ai.html","id":"machine-learning-and-statistics","chapter":"8 Machine learning and artificial intelligence","heading":"8.2.1 Machine learning and statistics","text":"briefly mentioned , ML put context \ndata-analytic practices, including classical statistical analysis causal\ninference, among others. true ML statistical\nmethods overlap. example, logistic regression can applied binary\nclassification task (ML method) task estimating \nprobability outcome present absent given covariate values (\ncommon statistical method).ML tends focus model performance, measure well output\ncan associated inputs, especially inputs ML hasn’t seen yet;\ncalled --sample performance. contrast, statistical applications\ntend focus internal structure goodness--fit analytic\nmodel, typically intending assist explanation. contrast \nsometimes described terms ML focusing \\(\\widehat{y}\\), denoting \nestimated value response, statistics focusing \\(\\widehat{\\beta}\\),\ndenoting estimated model parameters, regression coefficients.ML tends handle complex nontraditional data structures better common\nstatistical methods , including images, free text, electronic health\nrecords, statistical models can also large complex. Statistical models\ntypically based explicitly constructed probability models; although \nmodels can large complex, size complexity might constrained \nfacilitate interpretability model. contrast, since ML models tend \nfocus performance rather interpretability, complexity \nacceptable added model complexity improves model performance \navoids disadvantages overfitting.ML tends handle larger numbers inputs, hence larger numbers model\nparameters, better common statistical methods. traditional statistical\npractice, several heuristics might used constrain model size, including\nstepwise variable selection, best---subsets regression, penalties \nforce tradeoff model fit model size. ML methods deal \npotentially large numbers inputs 2 main ways: feature engineering, \nseeks derive performative inputs old inputs (one example \nprincipal components), regularization, trades model\nperformance model size figuring ways downweight upweight inputs\noptimizing --sample performance. sure, statistical models can \nuse techniques described ML models.Typical differences machine learning statisticsI listed 3 main contrasts ML statistics: (1) focus model\nperformance vs model fit, (2) facility complex nontraditional data\nstructures, (3) facility larger numbers inputs. sharp,\nexclusive distinctions, distinctions. Even \ndifferences orientation approach, ML, statistical, \ndata-analytic models subjected similar levels scrutiny \nrigor, well norms accuracy (many variations),\nfairness, bias mitigation, interpretability, explainability. note,\ninterpretability explainability can distractions, apparently\ninterpretable models necessarily closer true complex \nobscure models.Just ML put context data-analytic methods \npractices, AI put context data-analytic\napplications. Although AI often implemented automate assist tasks\nscale, decision-making, data-analytic methods similarly\nundergird practical applications. example, Framingham risk score,\ncommonly used medical practice, derived empirical data thousands\nparticipants. Many algorithms similarly empirically derived. \napplications AI applications share common concerns:underlying data-analytic models conform scientific norms?underlying data-analytic models conform scientific norms?models subject undue bias characteristics \naffect limit applicability?models subject undue bias characteristics \naffect limit applicability?limitations breach ethical, legal, social norms, example, \nimposing leading unfair conditions outcomes?limitations breach ethical, legal, social norms, example, \nimposing leading unfair conditions outcomes?concerns pertain algorithmic decision-making general rather\nAI particular. unique concerns, however, arise potential\nAI applications especially complex dynamic continuing learn\naccruing data, challenges identifying conditions sets \ninput values model performs especially poorly identifying\nchanges model performance training data accumulate time.","code":""},{"path":"ml-ai.html","id":"on-predictive-analytics-ml-and-ai","chapter":"8 Machine learning and artificial intelligence","heading":"8.2.2 On “predictive analytics”, ML, and AI","text":"early days CDC’s Public Health Data Strategy, asserted \n“predictive analytic tools machine learning” hold answers \nmodernization. assertion seems assume perfect, high-speed data can\ninevitably support informed action intervene public health, especially\noutbreaks, best methods used. example, one presentation said\n“reality” “looking back: using data see already\nhappened” “opportunity” “looking forward: using data predict \nprevent threats” (original emphasis). presentation asserted goal\n“transform CDC partners culture primarily historical data\nanalytics predictive data science …”.doubt better data lead better learning, analytic methods must\nalso adequately account limits information inherent \ncombination data methods; otherwise, risk mismatching expectations\nrealistic possibility. emphasis “predictive analytics” \nacknowledge real limits even best data tips (likely\nunintended) undervaluing cumulatively understanding history. AI might \nmight aid making better decisions. Data-analytic workflows can improve\nability forecast, anticipate, preemptively intervene, \ntake care tip balance far. Even able attend \ncompletely possible forward-looking workflows, still \nprimarily (emphasis) looking back see already happened.\nGetting smarter nimble future still requires us remain\nrooted history. like see responsible treatment use \navailable tools—classical conventional, statistics machine learning,\ncorrelation causation—yet available, achieve public\nhealth practice less exclusively reactive reactionary.","code":""},{"path":"ml-ai.html","id":"context-history","chapter":"8 Machine learning and artificial intelligence","heading":"8.3 Context: history","text":"January 2022 report Protecting Integrity Government Science \nScientific Integrity Fast-Track Action Committee states:New technology new approaches science—big data analytics, AI,\nML—become central many areas science Federal\ndecision-making. technological advances provide opportunities \ndeeply efficiently learn world, also present unique\nchallenges complexities ensuring scientific integrity. …\nAdditionally, scientific integrity policies can extended offices \nwork units traditionally focused research make use \nresults AI ML-based analyses.”\n(Scientific Integrity Fast-Track Action Committee 2022, p 27-28)passage includes rare important acknowledgment data analyses,\nincluding nonresearch, come policies scientific\nintegrity. Like “predictive analytics” example , however, overstates\n“new approaches” “unique challenges complexities” stemming ML\nAI. Although AI can introduce complex issues assistance automation\ntechnologies, upstream issues arise data analysis \nespecially unique ML AI.People CDC often talk ML AI new methods new technology. \nmethods, especially associated deep learning, relatively new \nyet potential familiar widespread use search\nengines smartphones. methods uses ML go back decades. \nexample, early neural networks became popular 1980s, classification \nregression trees publicized 1984, support vector machines 1990s,\nrandom forests 2001. isn’t quibble history much \nencouragement see methods perhaps unfamiliar rather new, \nrealize methods subjected vigorous, often\nrigorous, analysis, testing, scrutiny. Thus, can applied \nnormative confidence similar familiar methods comparable complexity\nwell subject similar scrutiny.mentioned , ML AI can complex familiar\nstatistical methods applications, ML AI inherit longstanding\nissues common forms data analysis applications, including bias\nprivacy concerns. regard, data analytic efforts take\ncare elucidate potential biases promote transparency. data\ncomplex methods complex, efforts warrant special attention\nperhaps special methods complexity. Whether complex\nBayesian methods, methods using rich electronic health records, multilevel\nsurveys, data synthesized sources varying content quality, \ncomplex data complex methods warrant critical scientific thinking \nproblem-solving, use ML AI. contrast, concerns arise\nuncritical reliance assistive automating algorithms, unique\ncriticism inheres uncritical reliance algorithms\n.Furthermore, many ML methods already applied public health problems\nhundreds published, peer-reviewed manuscripts. Many dozens \nmanuscripts either included author CDC ATSDR affiliation \nresulted project funded CDC/ATSDR. See, example, Goertzel et al. (2006),\nHolt et al. (2009),\nMenon et al. (2014),\nGu et al. (2015),\nPetersen et al. (2015),\nBertke et al. (2016),\nLadd-Acosta et al. (2016),\nMaenner et al. (2016),\nRubaiyat et al. (2016),\nArnold et al. (2017),\nGoldstick et al. (2017),\nKracalik et al. (2017),\nBowen et al. (2018),\nMeyers et al. (2018),\nYanamala et al. (2018),\nLee, Levin, et al. (2019),\nLee, Maenner, et al. (2019), \nWheeler (2019).\npublications span applications infectious noninfectious conditions\nwell cross-cutting areas like syndromic surveillance. entail ML\nmethods include regularized regression, decision trees tree-based\nensembles (like random forests gradient-boosting machines), support vector\nmachines, ensemble methods (like super learner), variety \nshallow deep neural network architectures. Although \npublications use supervised learning methods, especially classification,\nmany use unsupervised methods, topic modeling.current context, CDC positioned continue contributing rigorous work\nemploys ML methods, especially base R Python users grows\nwithin agency take advantage high-quality, open-source tools. CDC’s\ngreater technical challenges moment entail incremental uptake \ncloud-enabled technologies supporting operations deploying trained\nmodels, especially deep learning models use graphics processing unit (GPU)\nhardware. Early efforts proven models stymied procedural\nglitches prevent real implementation AI. Nonetheless, AI \nseeing ever-expanding collection useful applications clinical medicine,\nprospects strong public health applications. example, methods\nusing rich, possibly messy electronic health records hold promise \napplications varied self-adapting triggers electronic case reporting,\nenriching use emergency departments sources syndromic\nsurveillance, forecasting population prevalence wide variety \nconditions, including autism spectrum disorder Parkinson’s disease. ML might\nmight help general forecasting outbreak analysis, \nstatistical methods suited purposes warrant much\ndevelopmental attention ML .","code":""},{"path":"ml-ai.html","id":"context-organizational-culture","chapter":"8 Machine learning and artificial intelligence","heading":"8.4 Context: organizational culture","text":"try imagine possible applications ML AI CDC’s mission,\nalso conceptualize ML AI normalized within \norganizational structure. already happened, continue happen,\nevery center CDC uses ML way. Yet central leadership\nML AI.Foremost, ML undergirds AI, ML data-analytic\napproaches similarly subject scientific norms, follows ML\nrather AI drive growth practice. CDC promotes AI \nbalance ML, risk deploying technologies purported solutions\nhold scientific scrutiny, --sample performance,\nbias, drift go underappreciated undermine scientific integrity.Furthermore, efforts fortify workforce capacity focus primarily \nanalytic literacy, including critical thinking assessment. CDC\nunquestionably needs ML engineers technology-adept skills, roles\nskills need carried within bounds credible scientific\npractice. draw general discussion section 4 \nfoster culture good things data investing \ntechnical skills, nontechnical skills, community, tailored ML \nAI. Many skills already exist CDC’s existing workforce, largely\nunderrecognized underappreciated. CDC can come recognize \nappreciate existing technical nontechnical skills among current federal\nemployees, fellows learners, nonfederal staff, can build\nskills faster. Moreover, work toward expanding capacity ML \nAI, include current data-analytic practitioners (including \nuse ML) leading efforts. Finally, build capacity, need \nbalance innovation respect history. continue \nexpand set tools available us learning data building\nthings using data, can’t afford lose sight existing methods also\nserve purposes.Department Health Human Services locates AI leadership within \nOffice Chief Information\nOfficer. view,\noffice predicated fundamental category errors threaten \nconstrain misdirect efforts use apply full set methods \nlearning data building things data. office’s definition\nML “type artificial intelligence” (HHS OCIO 2021)\nobscures reveals. framing precedent, MIT’s\nmanagement school presents ML subfield artificial intelligence\n(Brown 2021). argued , ML methods “learn” data,\nML data analysis; argue ML judged ways\nsimilar empirical, specifically data-analytic, approaches. \nimportant see ML connected full range data-analytic methods \ntools, least 2 reasons: (1) Statistical machine learning methods, \ndata-analytic methods (causal inference), formal methods\ncharacterizing performance optimization, methods connect\nacross fields. ML just set methods unto , emphasizes\ncharacteristics differ domains. (2) subsuming ML AI, \nlose understanding even conventional, classical statistical methods can\ndrive AI, risk burdening ML practice broadly. Without grounding\nscience related norms, ML AI risk giving much privilege model\nperformance. Indeed, move delimit “trustworthy” AI seeks \ntrustworthiness norms reason. important concerns arise \nimplementing algorithms assist automate, can distinguish\nupstream issues, example, stem input data model structure.CDC develops central leadership ML AI, follow HHS’s\nlead aligning ML/AI primarily technology. Instead, CDC align\nML/AI primarily practice science, specifically data-intensive\nscience, norms entails. argued , technology\ntake lead scientific interests. Technology can help show \npossible, neither push limit possible, within\nresource security constraints. Technology respond empower\nscientific advances.","code":""},{"path":"declaration.html","id":"declaration","chapter":"Appendix A Declaration: a progressive culture for data in public health","heading":"Appendix A Declaration: a progressive culture for data in public health","text":"progressive culture data public health keeps fast-moving\nmethods, tools, technology continuously learning things world\nempowering choices informed learnings. declaration frames \nmajor elements cultivating sustaining progressive culture \nleading public health modern era. Public health scientists care\ndata can flourish culture fosters technical skills, inspires \nrewards intellectual drive, supports learners community.Technical skills include math statistics, programming data\nstructures, communications visualization, domain knowledge public\nhealth allied fields.Technical skills include math statistics, programming data\nstructures, communications visualization, domain knowledge public\nhealth allied fields.Nontechnical skills put traits good learner knower action,\nmotivating enabling care data learn practice\nwisely.Nontechnical skills put traits good learner knower action,\nmotivating enabling care data learn practice\nwisely.Support empowering good things data comes \ncommunity peers, mentors, advocates centered learning.Support empowering good things data comes \ncommunity peers, mentors, advocates centered learning.progressive culture data public health manifests following\nprinciples:Data object: progressive culture data dedicated learning\ndata. progressive culture, data value \nmediate learn things world. learnings allow us \nmake informed choices interact world, example,\npublic health interventions.Data object: progressive culture data dedicated learning\ndata. progressive culture, data value \nmediate learn things world. learnings allow us \nmake informed choices interact world, example,\npublic health interventions.Data subject: progressive culture data dedicated learning\ndata, data come many structures, sizes, shapes, \nspeeds, small, flat data tables massive, unstructured data streams.\nData conform variety standards, standards . varied\ncharacteristics complexity data enrich constrain ways\ndata reveal characteristics world.Data subject: progressive culture data dedicated learning\ndata, data come many structures, sizes, shapes, \nspeeds, small, flat data tables massive, unstructured data streams.\nData conform variety standards, standards . varied\ncharacteristics complexity data enrich constrain ways\ndata reveal characteristics world.Data mediator: progressive culture data dedicated learning\ndata full life cycle1, primarily\nknowing analytic methods allow us\npose rich questions world, amenable rich methods;\nguide generate, transmit, obtain, prepare data;\nprobe data answer questions world;\nplace answers data context, mindful assumptions \nalternatives;\npresent data-driven answers audiences clearly correctly;\npreserve answers ensure entire life cycle \ntransparent, accessible, traceable , extent possible,\nreproducible.\nData mediator: progressive culture data dedicated learning\ndata full life cycle1, primarily\nknowing analytic methods allow usto pose rich questions world, amenable rich methods;pose rich questions world, amenable rich methods;guide generate, transmit, obtain, prepare data;guide generate, transmit, obtain, prepare data;probe data answer questions world;probe data answer questions world;place answers data context, mindful assumptions \nalternatives;place answers data context, mindful assumptions \nalternatives;present data-driven answers audiences clearly correctly;present data-driven answers audiences clearly correctly;preserve answers ensure entire life cycle \ntransparent, accessible, traceable , extent possible,\nreproducible.preserve answers ensure entire life cycle \ntransparent, accessible, traceable , extent possible,\nreproducible.Community supports good things data 4 primary roles:\nLearner-practitioners basic intermediate data skills come\ndiscipline good things data, mindful full\nlife cycle data. progressive culture data, everyone \nwants good things data intellectual support ,\naccepting must proceed rigor stand behind work.\nPractitioners learn continuously show modern tools methods\nsolve modern problems.\nExpert practitioners go deep data science methods. Experts help\nensure everyone wants good things data, can. \nset norms practice data science learning , ,\ndata. enable, guide, correct, empower practitioners \nproceed rigor stand behind work.\nManagers supervise practitioners experts, ensure \nresources direction need achieve good things\ndata, now future. Managers foster reward curiosity,\ninvest learning (just training), encourage innovation \ninteresting mistakes. advocate means enable\npractitioners experts continue increasing capability,\nefficiency, effectiveness. Managers hold practitioners experts\naccount producing knowledge learned , , data.\nLay advocates work community practitioners, experts, \nmanagers persons literate value data help learn things\nworld. Laypersons know assess, use, advocate \nlearning data. help ensure supportive resources enable\nlearning.\nCommunity supports good things data 4 primary roles:Learner-practitioners basic intermediate data skills come\ndiscipline good things data, mindful full\nlife cycle data. progressive culture data, everyone \nwants good things data intellectual support ,\naccepting must proceed rigor stand behind work.\nPractitioners learn continuously show modern tools methods\nsolve modern problems.Learner-practitioners basic intermediate data skills come\ndiscipline good things data, mindful full\nlife cycle data. progressive culture data, everyone \nwants good things data intellectual support ,\naccepting must proceed rigor stand behind work.\nPractitioners learn continuously show modern tools methods\nsolve modern problems.Expert practitioners go deep data science methods. Experts help\nensure everyone wants good things data, can. \nset norms practice data science learning , ,\ndata. enable, guide, correct, empower practitioners \nproceed rigor stand behind work.Expert practitioners go deep data science methods. Experts help\nensure everyone wants good things data, can. \nset norms practice data science learning , ,\ndata. enable, guide, correct, empower practitioners \nproceed rigor stand behind work.Managers supervise practitioners experts, ensure \nresources direction need achieve good things\ndata, now future. Managers foster reward curiosity,\ninvest learning (just training), encourage innovation \ninteresting mistakes. advocate means enable\npractitioners experts continue increasing capability,\nefficiency, effectiveness. Managers hold practitioners experts\naccount producing knowledge learned , , data.Managers supervise practitioners experts, ensure \nresources direction need achieve good things\ndata, now future. Managers foster reward curiosity,\ninvest learning (just training), encourage innovation \ninteresting mistakes. advocate means enable\npractitioners experts continue increasing capability,\nefficiency, effectiveness. Managers hold practitioners experts\naccount producing knowledge learned , , data.Lay advocates work community practitioners, experts, \nmanagers persons literate value data help learn things\nworld. Laypersons know assess, use, advocate \nlearning data. help ensure supportive resources enable\nlearning.Lay advocates work community practitioners, experts, \nmanagers persons literate value data help learn things\nworld. Laypersons know assess, use, advocate \nlearning data. help ensure supportive resources enable\nlearning.Members progressive culture data respect fundamentals, value\ninnovation, practice pragmatic, principled pluralism. Members apply\nwisely well methods can help achieve technical excellence\nlearn , , data. methods include classical,\nconventional, innovative; statistics machine learning;\ncorrelational, causal, predictive inference; analysis, synthesis, \nforecasting. Principled pluralism allows honest disagreement methods,\nresults, interpretation.Members progressive culture data respect fundamentals, value\ninnovation, practice pragmatic, principled pluralism. Members apply\nwisely well methods can help achieve technical excellence\nlearn , , data. methods include classical,\nconventional, innovative; statistics machine learning;\ncorrelational, causal, predictive inference; analysis, synthesis, \nforecasting. Principled pluralism allows honest disagreement methods,\nresults, interpretation.progressive culture data public health fosters public trust,\nmotivated public service conduct ethically, protect\nprivacy, ensure data methods radically open \ntransparent.progressive culture data public health fosters public trust,\nmotivated public service conduct ethically, protect\nprivacy, ensure data methods radically open \ntransparent.progressive culture data, leadership radically \nintentionally inclusive, continually shaping sustaining culture \ngood data practice. Practitioners, experts, managers, laypersons lead\nevery level, regardless career stage, job title, credential,\njob series, everyone wants good things data, can.\nprogressive culture data, governance enables effective leadership,\ngovernance substitute leadership.progressive culture data, leadership radically \nintentionally inclusive, continually shaping sustaining culture \ngood data practice. Practitioners, experts, managers, laypersons lead\nevery level, regardless career stage, job title, credential,\njob series, everyone wants good things data, can.\nprogressive culture data, governance enables effective leadership,\ngovernance substitute leadership.public health sector faces constant challenges stretch modest resources,\nanticipate respond threats, promote population health. \nprogressive culture remains rooted history continues learn old\ndata new ways, anticipates future handles evolving demands \nkeep fast-moving methods, tools, technology. Cultivating \nprogressive data culture present best position field public\nhealth ever ready learn act data.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
